{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a0ef9e7",
   "metadata": {},
   "source": [
    "Paper内容主要被明确划分为了3部分：\n",
    "1. Title：论文标题。\n",
    "2. Abstract：论文摘要。\n",
    "3. Main：论文正文，包括Introduction、Methodology、Conclusion等内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bb9610",
   "metadata": {},
   "source": [
    "主要使用SciPDF Parser进行解析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815519fa",
   "metadata": {},
   "source": [
    "# 一、paper部分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4eb0f8",
   "metadata": {},
   "source": [
    "## 1. 解析pdf文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419d510",
   "metadata": {},
   "source": [
    "1. 运行SciPDF解析环境\n",
    "```shell\n",
    "# 公司GPU服务器\n",
    "bash /data/temp/paper_parsers/promote-openreview/scipdf_parser/serve_grobid.sh\n",
    "```\n",
    "\n",
    "2. 使用SciPDF解析文件夹中的PDF文件\n",
    "```shell\n",
    "python /data/temp/paper_parsers/promote-openreview/pdf_parser/scipdf_parser.py --dir_path <论文PDF所在文件夹>\n",
    "```\n",
    "\n",
    "3. 解析后得到的json文件将存放在同目录下的“scipdf_parser_results文件夹”中\n",
    "```shell\n",
    "/data/temp/paper_parsers/promote-openreview/pdf_parser/scipdf_parser_results\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06b2af0",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 指定未经处理的paper文件和未经处理的review文件的路径\n",
    "scipdf_path = r\"/Users/theon/Desktop/CV_project/julyacademic_gpt/process_data/已解析但待处理的数据(5000篇)/papers\"\n",
    "review_jsonl_path = r\"/Users/theon/Desktop/CV_project/julyacademic_gpt/process_data/已解析但待处理的数据(5000篇)/reviews/notes.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5520eba1",
   "metadata": {},
   "source": [
    "## 2. 读取paper json文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4fe1938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定必要库\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "674e8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取解析出的json文件并组成dataframe\n",
    "#df_sci = pd.DataFrame()\n",
    "#for json_file in tqdm(Path(scipdf_path).glob(\"*.json\")):\n",
    "#    with open(json_file, \"r\") as fp:\n",
    "#        dic = json.load(fp)\n",
    "#        dic[\"forum\"] = json_file.stem\n",
    "#    df_sci = df_sci.append(dic, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8cd9316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [00:01, 3442.25it/s]\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "for json_file in tqdm(Path(scipdf_path).glob(\"*.json\")):\n",
    "    with open(json_file, \"r\") as fp:\n",
    "        dic = json.load(fp)\n",
    "        dic[\"forum\"] = json_file.stem\n",
    "        data_list.append(dic)\n",
    "\n",
    "df_sci = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1861a209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'authors', 'pub_date', 'abstract', 'sections', 'references',\n",
       "       'figures', 'formulas', 'doi', 'forum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sci.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f14168",
   "metadata": {},
   "source": [
    "## 3. 处理main（正文）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4647699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理可疑换行符，将可疑换行符处理成\\n\n",
    "# 将\\n\\n\\n以及\\n\\n转为\\n\n",
    "# 去掉各种疑似\\\\n\n",
    "regex_3n = re.compile(r\"\\n\\n\\n\", flags=(re.S))\n",
    "regex_spn = re.compile(r\"\\n \\n\", flags=(re.S))\n",
    "regex_sln = re.compile(r\"\\\\n\", flags=(re.S))\n",
    "regex_2n = re.compile(r\"\\n\\n\", flags=(re.S))\n",
    "\n",
    "regexs_n = {\n",
    "    \"regex_3n\": regex_3n,\n",
    "    \"regex_spn\": regex_spn,\n",
    "    \"regex_sln\": regex_sln,\n",
    "    \"regex_2n\": regex_2n\n",
    "}\n",
    "def replace_1n(content, regexs=regexs_n):\n",
    "    content = re.sub(regexs[\"regex_3n\"], \"\\n\", content)\n",
    "    content = re.sub(regexs[\"regex_spn\"], \"\\n\", content)\n",
    "    content = re.sub(regexs[\"regex_sln\"], \"\\n\", content)\n",
    "    content = re.sub(regexs[\"regex_2n\"], \"\\n\", content)\n",
    "    content = re.sub(regexs[\"regex_spn\"], \"\\n\", content)\n",
    "    content = re.sub(regexs[\"regex_2n\"], \"\\n\", content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b2f913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       PAPER Introduction:\\nDeep neural networks (DNN...\n",
       "1       PAPER INTRODUCTION:\\nDeep neural networks (DNN...\n",
       "2       PAPER INTRODUCTION:\\nDefining efficient optimi...\n",
       "3       PAPER INTRODUCTION:\\nSimply minimizing the sta...\n",
       "4       PAPER INTRODUCTION:\\nSupervised learning algor...\n",
       "                              ...                        \n",
       "4995    PAPER Introduction:\\nCurious free-play has bee...\n",
       "4996    PAPER INTRODUCTION:\\nAutomatic detection of so...\n",
       "4997    PAPER Introduction:\\nMachine learning is the p...\n",
       "4998    PAPER INTRODUCTION:\\n\"All samples are equal, b...\n",
       "4999    PAPER INTRODUCTION:\\nLearning discrete represe...\n",
       "Name: main, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将sections中的多个元素处理成单个文本，即main（正文）\n",
    "# PAPER {heading1}:\\n{text1}\\nPAPER_{heading2}:\\n{text2}...\n",
    "# 同时调用上方的replace_1n函数针对main处理多换行符、可疑换行符为单换行符\n",
    "\n",
    "def sctions2str(sections):\n",
    "    p_strings = []\n",
    "    for section in sections:\n",
    "        p_heading = section[\"heading\"]\n",
    "        p_text = section[\"text\"]\n",
    "        p_string = \"PAPER {}\".format(p_heading) + \":\\n\" + p_text\n",
    "        p_strings.append(p_string)\n",
    "    p_strings = \"\\n\".join(p_strings)\n",
    "    p_strings = replace_1n(p_strings)\n",
    "    return p_strings\n",
    "\n",
    "df_sci[\"main\"] = df_sci[\"sections\"].apply(lambda x: sctions2str(x))\n",
    "df_sci[\"main\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee1b49ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2450\n",
       "1    15049\n",
       "2     6876\n",
       "3     7712\n",
       "4     5523\n",
       "Name: main_count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计main单词数\n",
    "df_sci[\"main_count\"] = df_sci[\"main\"].map(lambda x: len(x.split()) if pd.notnull(x) else 0)\n",
    "df_sci[\"main_count\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e5266bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4800         0\n",
       "1703        95\n",
       "3017       112\n",
       "914        122\n",
       "2081       134\n",
       "         ...  \n",
       "2871     70799\n",
       "2597     79886\n",
       "225      93561\n",
       "976     103113\n",
       "1055    138736\n",
       "Name: main_count, Length: 5000, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看单词数排序\n",
    "# 发现存在单词数为0的情况，也有单词数高达140K的情况\n",
    "# 有必要进行一定的极端值处理操作\n",
    "df_sci[\"main_count\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ac93fa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001       151.982\n",
       "0.100      2128.000\n",
       "0.250      3942.000\n",
       "0.500      5343.000\n",
       "0.750      6846.250\n",
       "0.900      9557.600\n",
       "0.950     12321.000\n",
       "0.990     22538.570\n",
       "0.999     65616.188\n",
       "1.000    138736.000\n",
       "Name: main_count, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 观察main单词数的分位数情况\n",
    "# 可知140K单词数已属于极端情况、260的单词数也过短\n",
    "df_sci[\"main_count\"].quantile(q=[0.001, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99, 0.999, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "effa7937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 ==> 4448\n"
     ]
    }
   ],
   "source": [
    "# 去除正文长度大于99分位数以及小于10分位数的项（去极端值）\n",
    "df_sci_handle = df_sci[(df_sci[\"main_count\"] < df_sci[\"main_count\"].quantile(q=0.99)) & (df_sci[\"main_count\"] > df_sci[\"main_count\"].quantile(q=0.1))] \n",
    "print(\"{} ==> {}\".format(df_sci.shape[0], df_sci_handle.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429ce5c3",
   "metadata": {},
   "source": [
    "## 4. 处理title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef2f54a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Defending against Model Stealing via Verifying...\n",
       "1       EXPLAINING REPRESENTATION BOTTLENECKS OF CONVO...\n",
       "2       EFFICIENT WASSERSTEIN NATURAL GRADIENTS FOR RE...\n",
       "3       Under review as a conference paper at ICLR 202...\n",
       "4       SOME CONSIDERATIONS ON LEARNING TO EXPLORE VIA...\n",
       "                              ...                        \n",
       "4994    Why a Naive Way to Combine Symbolic and Latent...\n",
       "4995    Curious Exploration via Structured World Model...\n",
       "4997                       Self-Referential Meta Learning\n",
       "4998            LEARNING FROM SAMPLES OF VARIABLE QUALITY\n",
       "4999    SELF-SUPERVISED LEARNING OF DISCRETE SPEECH RE...\n",
       "Name: title_new, Length: 4448, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 针对title处理多换行符、可疑换行符为单换行符\n",
    "df_sci_handle[\"title_new\"] = df_sci_handle[\"title\"].apply(lambda x: replace_1n(x))\n",
    "df_sci_handle[\"title_new\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7acd193b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9\n",
       "1        7\n",
       "2        7\n",
       "3       18\n",
       "4        9\n",
       "        ..\n",
       "4994    15\n",
       "4995    10\n",
       "4997     3\n",
       "4998     6\n",
       "4999     6\n",
       "Name: title_new_count, Length: 4448, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计title单词数\n",
    "df_sci_handle[\"title_new_count\"] = df_sci_handle[\"title_new\"].map(lambda x: len(x.split()) if pd.notnull(x) else 0)\n",
    "df_sci_handle[\"title_new_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f9b1667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2965     0\n",
       "2142     0\n",
       "3541     0\n",
       "726      0\n",
       "2124     0\n",
       "        ..\n",
       "3240    25\n",
       "3101    26\n",
       "1050    26\n",
       "1790    28\n",
       "4768    61\n",
       "Name: title_new_count, Length: 4448, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看单词数排序\n",
    "# 发现存在单词数为0的情况，也有单词数高达148的情况，看上去似乎不太合乎常理\n",
    "# 有必要进行一定的极端值处理操作\n",
    "# 后续可以从review侧获取相应的title信息来填补\n",
    "df_sci_handle[\"title_new_count\"].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545668db",
   "metadata": {},
   "source": [
    "## 5. 处理abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca190c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Well-trained models are valuable intellectual ...\n",
       "1       In this paper, we prove representation bottlen...\n",
       "2       A novel optimization approach is proposed for ...\n",
       "3       A lot of theoretical and empirical evidence sh...\n",
       "4       We consider the problem of exploration in meta...\n",
       "                              ...                        \n",
       "4994    We compare a rule-based approach for knowledge...\n",
       "4995    It has been a long-standing dream to design ar...\n",
       "4997    Meta Learning automates the search for learnin...\n",
       "4998    Training labels are expensive to obtain and ma...\n",
       "4999    We propose vq-wav2vec to learn discrete repres...\n",
       "Name: abstract_new, Length: 4448, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 针对abstract处理多换行符、可疑换行符为单换行符\n",
    "df_sci_handle[\"abstract_new\"] = df_sci_handle[\"abstract\"].apply(lambda x: replace_1n(x))\n",
    "df_sci_handle[\"abstract_new\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a5e4edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       150\n",
       "1       163\n",
       "2        80\n",
       "3       164\n",
       "4        55\n",
       "       ... \n",
       "4994    100\n",
       "4995    191\n",
       "4997    121\n",
       "4998    147\n",
       "4999     79\n",
       "Name: abstract_new_count, Length: 4448, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计abstract单词数\n",
    "df_sci_handle[\"abstract_new_count\"] = df_sci_handle[\"abstract_new\"].map(lambda x: len(x.split()) if pd.notnull(x) else 0)\n",
    "df_sci_handle[\"abstract_new_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ccf3ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274        0\n",
       "1896       0\n",
       "1753       0\n",
       "1257       0\n",
       "3030       0\n",
       "        ... \n",
       "31      1142\n",
       "3936    1240\n",
       "2069    1384\n",
       "4497    1916\n",
       "1202    2067\n",
       "Name: abstract_new_count, Length: 4448, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看单词数排序\n",
    "# 发现存在单词数为0的情况\n",
    "# 有必要进行一定的极端值处理操作\n",
    "# 后续可以从review侧获取相应的abstract信息来填补\n",
    "df_sci_handle[\"abstract_new_count\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d86537b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'authors', 'pub_date', 'abstract', 'sections', 'references',\n",
       "       'figures', 'formulas', 'doi', 'forum', 'main', 'main_count',\n",
       "       'title_new', 'title_new_count', 'abstract_new', 'abstract_new_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 总览列名\n",
    "df_sci_handle.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee73c7",
   "metadata": {},
   "source": [
    "# 二、review部分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b1c2aa",
   "metadata": {},
   "source": [
    "由 https://gitee.com/remixa/promote-openreview/blob/master/utils/openreview_crawler.py 爬取得到，并存储为jsonl格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123589bb",
   "metadata": {},
   "source": [
    "## 1. 读取review jsonl文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66b329d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同 https://gitee.com/remixa/promote-openreview/blob/master/utils/openreview_processor.py\n",
    "# 定义读取器，将jsonl格式的review读取成dataframe格式\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "\n",
    "class openreview_proccessor():\n",
    "    def __init__(self, jsonl_path):\n",
    "        self.df = self._load_jsonl_to_dataframe(jsonl_path)\n",
    "        self.df_sub = pd.DataFrame()\n",
    "    \n",
    "    def _load_jsonl_to_dataframe(self, jsonl_path):\n",
    "        msg_list = []\n",
    "        with open(jsonl_path, 'r', encoding='utf-8') as file:\n",
    "            for line_dict in jsonlines.Reader(file):\n",
    "                msg_dict = {}\n",
    "                for k, v in line_dict['basic_dict'].items():\n",
    "                    msg_dict['b_' + k] = v\n",
    "                msg_list.append(msg_dict)\n",
    "                for review_msg in line_dict[\"reviews_msg\"]:\n",
    "                    msg_dict_copy = msg_dict.copy()\n",
    "                    pure_review_msg = {\n",
    "                        'r_id': review_msg.get('id', None),\n",
    "                        'r_number': review_msg.get('number', None),\n",
    "                        'r_replyto': review_msg.get('replyto', None),\n",
    "                        'r_invitation': review_msg.get('invitation', None),\n",
    "                        'r_signatures': ','.join(review_msg['signatures']) if review_msg.get('signatures', None) else None,\n",
    "                        'r_readers': review_msg.get('readers', None),\n",
    "                        'r_nonreaders': review_msg.get('nonreaders', None),\n",
    "                        'r_writers': review_msg.get('writers', None)  \n",
    "                    }\n",
    "                    pure_content_msg = {}\n",
    "                    pure_content_msg['c_content'] = review_msg['content']\n",
    "                    for k, v in review_msg['content'].items(): \n",
    "                        pure_content_msg['c_' + k] = v\n",
    "                    pure_review_msg.update(pure_content_msg)\n",
    "                    msg_dict_copy.update(pure_review_msg)\n",
    "                    msg_list.append(msg_dict_copy)\n",
    "        dataframe = pd.DataFrame(msg_list)\n",
    "        dataframe['c_final_decision'] = self._fill_decision(dataframe)\n",
    "        return dataframe\n",
    "    \n",
    "    def _fill_decision2(self, dataframe):\n",
    "        return dataframe['c_decision'].fillna('Unknown').map(lambda x: 'Accepted' if x.startswith('Accept') else \n",
    "                                                          'Rejected' if x.startswith('Reject') else x)\n",
    "    def _fill_decision(self, dataframe):\n",
    "        return dataframe['c_decision'].map(lambda x: x if pd.isnull(x) else\n",
    "                                           'Accepted' if 'accept' in x.lower() else \n",
    "                                            'Rejected' if 'reject' in x.lower() else \"Unknown\")\n",
    "    \n",
    "    def get_sub(self, mode=None):\n",
    "        # 仅带有review的df\n",
    "        df_sub = self.df.dropna(subset=self.df.filter(regex='^(?!b_*)').columns, how='all')\n",
    "        if mode == 'decision':\n",
    "            # review类型仅为decision的df\n",
    "            df_sub = df_sub[df_sub['r_invitation'].str.contains('Decision')]\n",
    "        elif mode == 'other':\n",
    "            # review类型仅为非decision的df\n",
    "            df_sub = df_sub[~df_sub['r_invitation'].str.contains('Decision')]\n",
    "        elif mode == 'accepted':\n",
    "            # decision中被采纳的df\n",
    "            df_sub = df_sub[df_sub['c_final_decision'].isin(['Accepted'])]\n",
    "        elif mode == 'rejected':\n",
    "            # decision中未被采纳的df\n",
    "            df_sub = df_sub[df_sub['c_final_decision'].isin(['Rejected'])]\n",
    "\n",
    "        self.df_sub = df_sub\n",
    "        return\n",
    "    \n",
    "    def get_total_shape(self):\n",
    "        return self.df.shape\n",
    "    \n",
    "    def get_sub_shape(self):\n",
    "        return self.df_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3d27d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b_forum</th>\n",
       "      <th>b_title</th>\n",
       "      <th>b_url</th>\n",
       "      <th>b_pub_date</th>\n",
       "      <th>b_abstract</th>\n",
       "      <th>b_TL;DR</th>\n",
       "      <th>b_authors</th>\n",
       "      <th>b_keywords</th>\n",
       "      <th>b_venue</th>\n",
       "      <th>b_venue_id</th>\n",
       "      <th>...</th>\n",
       "      <th>c_overall_recommendation</th>\n",
       "      <th>c_preliminary_rating</th>\n",
       "      <th>c_suggested_changes</th>\n",
       "      <th>c_reason_for_not_giving_a_higher_recommendation</th>\n",
       "      <th>c_reason_for_not_giving_a_lower_recommendation</th>\n",
       "      <th>c_comments_and_feedback_to_the_authors</th>\n",
       "      <th>c_consent_to_archive</th>\n",
       "      <th>c_Reviewer expertise</th>\n",
       "      <th>c_Review (Strengths/Weaknesses)</th>\n",
       "      <th>c_final_decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>https://openreview.net/forum?id=ryjw_eAaZ</td>\n",
       "      <td>--</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>A principled approach for structure learning o...</td>\n",
       "      <td>Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...</td>\n",
       "      <td>unsupervised learning,structure learning,deep ...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>https://openreview.net/forum?id=ryjw_eAaZ</td>\n",
       "      <td>--</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>A principled approach for structure learning o...</td>\n",
       "      <td>Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...</td>\n",
       "      <td>unsupervised learning,structure learning,deep ...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>https://openreview.net/forum?id=ryjw_eAaZ</td>\n",
       "      <td>--</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>A principled approach for structure learning o...</td>\n",
       "      <td>Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...</td>\n",
       "      <td>unsupervised learning,structure learning,deep ...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>https://openreview.net/forum?id=ryjw_eAaZ</td>\n",
       "      <td>--</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>A principled approach for structure learning o...</td>\n",
       "      <td>Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...</td>\n",
       "      <td>unsupervised learning,structure learning,deep ...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rye7IMbAZ</td>\n",
       "      <td>Explicit Induction Bias for Transfer Learning...</td>\n",
       "      <td>https://openreview.net/forum?id=rye7IMbAZ</td>\n",
       "      <td>--</td>\n",
       "      <td>In inductive transfer learning, fine-tuning pr...</td>\n",
       "      <td>In inductive transfer learning, fine-tuning pr...</td>\n",
       "      <td>Xuhong LI,Yves GRANDVALET,Franck DAVOINE</td>\n",
       "      <td>transfer Learning,convolutional networks,fine-...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     b_forum                                            b_title  \\\n",
       "1  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "2  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "3  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "4  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "6  rye7IMbAZ   Explicit Induction Bias for Transfer Learning...   \n",
       "\n",
       "                                       b_url b_pub_date  \\\n",
       "1  https://openreview.net/forum?id=ryjw_eAaZ         --   \n",
       "2  https://openreview.net/forum?id=ryjw_eAaZ         --   \n",
       "3  https://openreview.net/forum?id=ryjw_eAaZ         --   \n",
       "4  https://openreview.net/forum?id=ryjw_eAaZ         --   \n",
       "6  https://openreview.net/forum?id=rye7IMbAZ         --   \n",
       "\n",
       "                                          b_abstract  \\\n",
       "1  We introduce an unsupervised structure learnin...   \n",
       "2  We introduce an unsupervised structure learnin...   \n",
       "3  We introduce an unsupervised structure learnin...   \n",
       "4  We introduce an unsupervised structure learnin...   \n",
       "6  In inductive transfer learning, fine-tuning pr...   \n",
       "\n",
       "                                             b_TL;DR  \\\n",
       "1  A principled approach for structure learning o...   \n",
       "2  A principled approach for structure learning o...   \n",
       "3  A principled approach for structure learning o...   \n",
       "4  A principled approach for structure learning o...   \n",
       "6  In inductive transfer learning, fine-tuning pr...   \n",
       "\n",
       "                                           b_authors  \\\n",
       "1  Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...   \n",
       "2  Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...   \n",
       "3  Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...   \n",
       "4  Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...   \n",
       "6           Xuhong LI,Yves GRANDVALET,Franck DAVOINE   \n",
       "\n",
       "                                          b_keywords b_venue b_venue_id  ...  \\\n",
       "1  unsupervised learning,structure learning,deep ...      --         --  ...   \n",
       "2  unsupervised learning,structure learning,deep ...      --         --  ...   \n",
       "3  unsupervised learning,structure learning,deep ...      --         --  ...   \n",
       "4  unsupervised learning,structure learning,deep ...      --         --  ...   \n",
       "6  transfer Learning,convolutional networks,fine-...      --         --  ...   \n",
       "\n",
       "   c_overall_recommendation c_preliminary_rating c_suggested_changes  \\\n",
       "1                       NaN                  NaN                 NaN   \n",
       "2                       NaN                  NaN                 NaN   \n",
       "3                       NaN                  NaN                 NaN   \n",
       "4                       NaN                  NaN                 NaN   \n",
       "6                       NaN                  NaN                 NaN   \n",
       "\n",
       "  c_reason_for_not_giving_a_higher_recommendation  \\\n",
       "1                                             NaN   \n",
       "2                                             NaN   \n",
       "3                                             NaN   \n",
       "4                                             NaN   \n",
       "6                                             NaN   \n",
       "\n",
       "  c_reason_for_not_giving_a_lower_recommendation  \\\n",
       "1                                            NaN   \n",
       "2                                            NaN   \n",
       "3                                            NaN   \n",
       "4                                            NaN   \n",
       "6                                            NaN   \n",
       "\n",
       "  c_comments_and_feedback_to_the_authors  c_consent_to_archive  \\\n",
       "1                                    NaN                   NaN   \n",
       "2                                    NaN                   NaN   \n",
       "3                                    NaN                   NaN   \n",
       "4                                    NaN                   NaN   \n",
       "6                                    NaN                   NaN   \n",
       "\n",
       "  c_Reviewer expertise c_Review (Strengths/Weaknesses) c_final_decision  \n",
       "1                  NaN                             NaN              NaN  \n",
       "2                  NaN                             NaN              NaN  \n",
       "3                  NaN                             NaN              NaN  \n",
       "4                  NaN                             NaN         Rejected  \n",
       "6                  NaN                             NaN              NaN  \n",
       "\n",
       "[5 rows x 191 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取review\n",
    "orp = openreview_proccessor(review_jsonl_path)\n",
    "orp.get_sub()\n",
    "# 原数据中存在部分数据是无review的情况，仅取带review的数据\n",
    "df_reviews = orp.df_sub\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319c637",
   "metadata": {},
   "source": [
    "## 2. 处理review文本（c_content）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3422ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        {'title': 'There is a major technical flaw in ...\n",
       "2        {'title': 'Interesting unsupervised structure ...\n",
       "3        {'title': 'Promising method, inconclusive resu...\n",
       "4        {'decision': 'Reject', 'title': 'ICLR 2018 Con...\n",
       "6        {'title': 'well written, needs more comparison...\n",
       "                               ...                        \n",
       "25462    {'title': 'Review of paper 1', 'review': 'This...\n",
       "25464    {'title': 'Risk-based ring vaccination appears...\n",
       "25465    {'title': 'This paper proposed a risk-based ri...\n",
       "25466    {'title': 'Review of the paper on risk-based r...\n",
       "25467    {'title': 'Review of risk-based ring vaccinati...\n",
       "Name: c_content, Length: 20486, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c_content字段即为dict格式的正文\n",
    "df_reviews[\"c_content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0577e",
   "metadata": {},
   "source": [
    "### I. 去除author回复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53a810f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20486 ==> 18456\n"
     ]
    }
   ],
   "source": [
    "# review中夹杂着论文author自己的回复，属于无用信息需要去除\n",
    "# 去除review中的author回复\n",
    "df_reviews_handle = df_reviews[~df_reviews[\"r_signatures\"].str.contains(\"Author\")]\n",
    "print(\"{} ==> {}\".format(df_reviews.shape[0], df_reviews_handle.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ebb367",
   "metadata": {},
   "source": [
    "### II. 去除低频子标题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be8b940a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.100        5.600\n",
       "0.200       16.000\n",
       "0.250       17.000\n",
       "0.500       53.000\n",
       "0.750      259.500\n",
       "0.900     3368.800\n",
       "0.995     9933.910\n",
       "0.999    11874.782\n",
       "1.000    12360.000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一些出现次数较少的标题可能会作为噪声存在，影响模型训练\n",
    "# 统计review内容中子标题出现的分位数\n",
    "# 大概10%的标题出现了5.8次，20%的标题出现了54.4次，...\n",
    "df_reviews_handle.filter(regex='^c_*').filter(regex='^(?!c_conten*)').notnull().sum().quantile(q=[0.1, 0.2, 0.25, 0.5, 0.75, 0.9, 0.995, 0.999,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6afc0bed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['c_withdrawal confirmation',\n",
       "       'c_[Optional] Respond to feedback request by the authors',\n",
       "       'c_metaReview', 'c_recommendation_for_accepted_papers',\n",
       "       'c_overall evaluation', 'c_reviewer's confidence', 'c_significance',\n",
       "       'c_scholarship', 'c_Bio_Award', 'c_reviews_visibility', 'c_novelty',\n",
       "       'c_pdf', 'c_zip_file', 'c_strengths_weaknesses', 'c_expertise',\n",
       "       'c_useful', 'c_writing', 'c_superlative', 'c_Sufficiently Alt',\n",
       "       'c_Conflicts', 'c_Review Inclusion', 'c_reviewtext',\n",
       "       'c_problemstatement', 'c_litreview', 'c_accessibility', 'c_results',\n",
       "       'c_reviewerconfidence', 'c_groundsforrejection', 'c_consent_to_archive',\n",
       "       'c_Reviewer expertise', 'c_Review (Strengths/Weaknesses)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看出现次数少于0.2分位数（即54.4次）的子标题\n",
    "df_reviews_handle.filter(regex='^c_*').filter(regex='^(?!c_conten*)').notnull().sum()[(df_reviews_handle.filter(regex='^c_*').filter(regex='^(?!c_conten*)').notnull().sum() < df_reviews_handle.filter(regex='^c_*').filter(regex='^(?!c_conten*)').notnull().sum().quantile(q=0.2))].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c66c6afb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['c_title', 'c_rating', 'c_review', 'c_confidence', 'c_decision',\n",
       "       'c_comment', 'c_metareview', 'c_recommendation',\n",
       "       'c_experience_assessment',\n",
       "       'c_review_assessment:_thoroughness_in_paper_reading',\n",
       "       ...\n",
       "       'c_submission_track', 'c_overall_rating', 'c_recommended_decision',\n",
       "       'c_overall_recommendation', 'c_preliminary_rating',\n",
       "       'c_suggested_changes',\n",
       "       'c_reason_for_not_giving_a_higher_recommendation',\n",
       "       'c_reason_for_not_giving_a_lower_recommendation',\n",
       "       'c_comments_and_feedback_to_the_authors', 'c_final_decision'],\n",
       "      dtype='object', length=127)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看大于0.2分位数的相对高频子标题\n",
    "\n",
    "df_reviews_rest_subtitle = df_reviews_handle.filter(regex='^(?!c_conten*)')[df_reviews_handle.filter(regex='^c_*').filter(regex='^(?!c_conten*)').notnull().sum()[(df_reviews_handle.filter(regex='^c_*').filter(regex='^(?!c_conten*)').notnull().sum() > df_reviews_handle.filter(regex='^c_*').filter(regex='^(?!c_conten*)').notnull().sum().quantile(q=0.2))].index]\n",
    "df_reviews_rest_subtitle.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb98db3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'rating',\n",
       " 'review',\n",
       " 'confidence',\n",
       " 'decision',\n",
       " 'comment',\n",
       " 'metareview',\n",
       " 'recommendation',\n",
       " 'experience_assessment',\n",
       " 'review_assessment:_thoroughness_in_paper_reading',\n",
       " 'review_assessment:_checking_correctness_of_experiments',\n",
       " 'review_assessment:_checking_correctness_of_derivations_and_theory',\n",
       " 'summary_of_the_paper',\n",
       " 'main_review',\n",
       " 'summary_of_the_review',\n",
       " 'correctness',\n",
       " 'technical_novelty_and_significance',\n",
       " 'empirical_novelty_and_significance',\n",
       " 'flag_for_ethics_review',\n",
       " 'details_of_ethics_concerns',\n",
       " 'Q1 Summary and contributions',\n",
       " 'Q2 Assessment of the paper',\n",
       " 'Q2(1) Originality/Novelty',\n",
       " 'Q2(2) Significance/Impact',\n",
       " 'Q2(3) Correctness/Technical quality',\n",
       " 'Q2(4) Quality of experiments (Optional)',\n",
       " 'Q2(5) Reproducibility',\n",
       " 'Q2(6) Clarity of writing',\n",
       " 'Q3 Main strengths',\n",
       " 'Q4 Main weakness',\n",
       " 'Q5 Detailed comments to the authors',\n",
       " 'Q6 Overall score',\n",
       " 'Q7 Justification for your score',\n",
       " 'Q8 Confidence in your score',\n",
       " 'Q9 Complying with reviewing instructions',\n",
       " 'Q10 Ethical concerns (Optional)',\n",
       " 'summary',\n",
       " 'Justification for rating',\n",
       " 'paper_type',\n",
       " 'strengths',\n",
       " 'weaknesses',\n",
       " 'detailed_comments',\n",
       " 'justification_of_rating',\n",
       " 'special_issue',\n",
       " 'questions_to_address_in_the_rebuttal',\n",
       " 'soundness',\n",
       " 'clarity',\n",
       " 'reproducibility',\n",
       " 'Overall Score',\n",
       " 'evaluation',\n",
       " 'intersection',\n",
       " 'importance_comment',\n",
       " 'technical_rigor',\n",
       " 'intersection_comment',\n",
       " 'rigor_comment',\n",
       " 'importance',\n",
       " 'category',\n",
       " 'clarity_comment',\n",
       " 'limitations_and_societal_impact',\n",
       " 'needs_ethics_review',\n",
       " 'ethics_review_area',\n",
       " 'time_spent_reviewing',\n",
       " 'code_of_conduct',\n",
       " 'ethical_concerns',\n",
       " 'ethical_issues',\n",
       " 'ethics_review',\n",
       " 'issues_acknowledged',\n",
       " 'issues_acknowledged_description',\n",
       " 'consistency_experiment',\n",
       " 'score',\n",
       " 'strengths_and_weaknesses',\n",
       " 'questions',\n",
       " 'limitations',\n",
       " 'ethics_flag',\n",
       " 'presentation',\n",
       " 'contribution',\n",
       " 'award',\n",
       " 'originality',\n",
       " 'technical_quality',\n",
       " 'clarity_of_presentation',\n",
       " 'impact',\n",
       " 'summary_of_recommendation',\n",
       " 'issues',\n",
       " 'reviewer_expertise',\n",
       " 'robotics_focus',\n",
       " 'quality_of_the_limitations_section',\n",
       " 'best_paper_nomination',\n",
       " 'Summary',\n",
       " 'Main review',\n",
       " 'Overall score',\n",
       " 'your_profile_and_conflicts_of_interest',\n",
       " 'anonymity_and_confidentiality',\n",
       " 'deanonymize_review',\n",
       " 'summary_of_contributions',\n",
       " 'potential_impact_on_the_field_of_AutoML',\n",
       " 'potential_impact_on_the_field_of_AutoML_rating',\n",
       " 'technical_quality_and_correctness',\n",
       " 'technical_quality_and_correctness_rating',\n",
       " 'clarity_rating',\n",
       " 'ethics_rating',\n",
       " 'overall_review',\n",
       " 'review_summary',\n",
       " 'review_rating',\n",
       " 'review_confidence',\n",
       " 'Ethical concerns',\n",
       " 'Confidence',\n",
       " 'Code of conduct acknowledgment',\n",
       " 'reproducibility_summary',\n",
       " 'familiar_with_the_original_paper',\n",
       " 'relevance',\n",
       " 'strength_and_weaknesses',\n",
       " 'clarity,_quality,_novelty_and_reproducibility',\n",
       " 'metareview:_summary,_strengths_and_weaknesses',\n",
       " 'summary_of_AC-reviewer_meeting',\n",
       " 'justification_for_why_not_higher_score',\n",
       " 'justification_for_why_not_lower_score',\n",
       " 'note_from_PC',\n",
       " 'submission_track',\n",
       " 'overall_rating',\n",
       " 'recommended_decision',\n",
       " 'overall_recommendation',\n",
       " 'preliminary_rating',\n",
       " 'suggested_changes',\n",
       " 'reason_for_not_giving_a_higher_recommendation',\n",
       " 'reason_for_not_giving_a_lower_recommendation',\n",
       " 'comments_and_feedback_to_the_authors',\n",
       " 'final_decision']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去除列名中的“c_”\n",
    "# \"c_\"是初期数据认知阶段用以区分基本信息（b_）、review信息(r_)、review正文（c_）时所添加的\n",
    "# 现需要根据相对高频的列名来从review正文c_content中保留高频子标题及其内容，剔除低频子标题及其内容\n",
    "\n",
    "rm_regex = re.compile(\"^c_(.*)\")\n",
    "def remove_c_(col, rm_regex=rm_regex):\n",
    "    res_col = re.search(rm_regex, col)\n",
    "    return res_col.group(1)\n",
    "\n",
    "# 获取需要保留的高频列名，并去除列名中的“c_”\n",
    "rest_subtitle = df_reviews_rest_subtitle.columns\n",
    "rest_subtitle = [remove_c_(rst) for rst in rest_subtitle]\n",
    "rest_subtitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d32a6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        REVIEW title:\\nThere is a major technical flaw...\n",
       "2        REVIEW title:\\nInteresting unsupervised struct...\n",
       "3        REVIEW title:\\nPromising method, inconclusive ...\n",
       "4        REVIEW decision:\\nReject\\nREVIEW title:\\nICLR ...\n",
       "6        REVIEW title:\\nwell written, needs more compar...\n",
       "                               ...                        \n",
       "25462    REVIEW title:\\nReview of paper 1\\nREVIEW revie...\n",
       "25464    REVIEW title:\\nRisk-based ring vaccination app...\n",
       "25465    REVIEW title:\\nThis paper proposed a risk-base...\n",
       "25466    REVIEW title:\\nReview of the paper on risk-bas...\n",
       "25467    REVIEW title:\\nReview of risk-based ring vacci...\n",
       "Name: c_content_str, Length: 18456, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基于上述余留子标题，处理c_content内的文本\n",
    "# 1. 去除上方提及的低频子标题（少于0.2分位数）\n",
    "# 2. 采用\\n拼接各个子标题\n",
    "# 3. 得到的文本格式为“REVIEW {子标题1}:\\n{子标题1相关内容}\\nREVIEW {子标题2}:\\n{子标题2相关内容}”\n",
    "\n",
    "def content_dict2str(content, rest=rest_subtitle):\n",
    "    strings = []\n",
    "    final_string = \"\"\n",
    "    for k, v in content.items():\n",
    "        # 剔除非保留项\n",
    "        if k not in rest:\n",
    "            continue\n",
    "        else:\n",
    "            sub_string = \"REVIEW {}:\\n{}\".format(k, v)\n",
    "            strings.append(sub_string)\n",
    "        final_string = \"\\n\".join(strings)\n",
    "    return final_string\n",
    "\n",
    "df_reviews_handle[\"c_content_str\"] = df_reviews_handle[\"c_content\"].apply(lambda x: content_dict2str(x))\n",
    "df_reviews_handle[\"c_content_str\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f070a9bc",
   "metadata": {},
   "source": [
    "### III. 去除reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b63e410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39       REVIEW title:\\nVery interesting work and the p...\n",
       "215      REVIEW title:\\nRelevant work, but not executed...\n",
       "343      REVIEW title:\\nInteresting paper but lacking i...\n",
       "369      REVIEW title:\\nReview\\nREVIEW rating:\\n7: Good...\n",
       "398      REVIEW title:\\nInteresting direction for explo...\n",
       "                               ...                        \n",
       "23958    REVIEW confidence:\\n5: You are absolutely cert...\n",
       "24027    REVIEW confidence:\\n3: You are fairly confiden...\n",
       "24183    REVIEW confidence:\\n2: You are willing to defe...\n",
       "24254    REVIEW title:\\nInteresting geometric-based met...\n",
       "25103    REVIEW title:\\nEasy to follow, reproducible wo...\n",
       "Name: c_content_str, Length: 247, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review本身文本量并不算大，但部分review会列举reference，导致reference占了review内容中较大的一部分\n",
    "# 且reference信息量都比较有限，因此需要将其从review文本中识别出来并剔除\n",
    "# 需要留意的是，不能单纯通过识别到“reference”这个词就断定是在列举参考文献\n",
    "# 因为确实存在只是提及了“reference”这个词的情况，并非是在列举参考文献\n",
    "# 需要撰写正则表达式对这种情况加以区分\n",
    "\n",
    "# 以\\nreference作为开头，以19XX.或20XX.作为结尾，这是列举一大段参考文献的范式，\n",
    "# 并且匹配模式设定为匹配换行符和忽略大小写\n",
    "# flags定义2种匹配模式，(re.S|re.I)分别指支持“匹配换行符（即匹配所有行，无需换行符隔开）”和“忽略大小写”\n",
    "regex = re.compile(\"\\n(reference)(.*)(19|20\\d+).*?\\.\", flags=(re.S|re.I))\n",
    "\n",
    "# 检查出列举有参考摘要的review\n",
    "def check_ref(content, regex=regex):\n",
    "    res = re.search(regex, content)\n",
    "    return res\n",
    "\n",
    "df_reviews_handle[df_reviews_handle[\"c_content_str\"].apply(lambda x: True if check_ref(x) else False)][\"c_content_str\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0f67edc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW title:\n",
      "Very interesting work and the proposed approach is well explained. The experimental section could be improved.\n",
      "REVIEW rating:\n",
      "8: Top 50% of accepted papers, clear accept\n",
      "REVIEW review:\n",
      "Summary:\n",
      "The manuscript extends the Neural Expectation Maximization framework by integrating an interaction function that allows asymmetric pairwise effects between objects. The network is demonstrated to learn compositional object representations which group together pixels, optimizing a predictive coding objective. The effectiveness of the approach is demonstrated on bouncing balls sequences and gameplay videos from Space Invaders. The proposed R-NEM model generalizes\n",
      "\n",
      "Review:\n",
      "Very interesting work and the proposed approach is well explained. The experimental section could be improved.\n",
      "I have a few questions/comments:\n",
      "1) Some limitations could have been discussed, e.g. how would the model perform on sequences involving more complicated deformations of objects than in the Space Invaders experiment? As you always take the first frame of the 4-frame stacks in the data set, do the objects deform at all?\n",
      "2) It would have been interesting to vary K, e.g. study the behaviour for K in {1,5,10,25,50}. In Space Invaders the model would probably really group together separate objects. What happens if you train with K=8 on sequences of 4 balls and then run on 8-ball sequences instead of providing (approximately) the right number of components both at training and test time (in the extrapolation experiment).\n",
      "3) One work that should be mentioned in the related work section is Michalski et al. (2014), which also uses noise and predictive coding to model sequences of bouncing balls and NORBvideos. Their model uses a factorization that also discovers relations between components of the frames, but in contrast to R-NEM the components overlap.\n",
      "4) A quantitative evaluation of the bouncing balls with curtain and Space Invaders experiments would be useful for comparison.\n",
      "5) I think the hyperparameters of the RNN and LSTM are missing from the manuscript. Did you perform any hyperparameter optimization on these models?\n",
      "6) Stronger baselines would improve the experimental section, maybe Seo et al (2016). Alternatively, you could train the model on Moving MNIST (Srivastava et al., 2015) and compare with other published results.\n",
      "\n",
      "I would consider increasing the score, if at least some of the above points are sufficiently addressed.\n",
      "\n",
      "References:\n",
      "Michalski, Vincent, Roland Memisevic, and Kishore Konda. \"Modeling deep temporal dependencies with recurrent grammar cells\"\".\" In Advances in neural information processing systems, pp. 1925-1933. 2014.\n",
      "Seo, Youngjoo, Michaël Defferrard, Pierre Vandergheynst, and Xavier Bresson. \"Structured sequence modeling with graph convolutional recurrent networks.\" arXiv preprint arXiv:1612.07659 (2016).\n",
      "Srivastava, Nitish, Elman Mansimov, and Ruslan Salakhudinov. \"Unsupervised learning of video representations using lstms.\" In International Conference on Machine Learning, pp. 843-852. 2015.\n",
      "REVIEW confidence:\n",
      "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n"
     ]
    }
   ],
   "source": [
    "# 任取其中一条来查看，可见其倒数第9行至倒数第3行确实是在列举参考文献\n",
    "print(df_reviews_handle[\"c_content_str\"].loc[39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61937ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b_forum</th>\n",
       "      <th>b_title</th>\n",
       "      <th>b_url</th>\n",
       "      <th>b_pub_date</th>\n",
       "      <th>b_abstract</th>\n",
       "      <th>b_TL;DR</th>\n",
       "      <th>b_authors</th>\n",
       "      <th>b_keywords</th>\n",
       "      <th>b_venue</th>\n",
       "      <th>b_venue_id</th>\n",
       "      <th>...</th>\n",
       "      <th>c_preliminary_rating</th>\n",
       "      <th>c_suggested_changes</th>\n",
       "      <th>c_reason_for_not_giving_a_higher_recommendation</th>\n",
       "      <th>c_reason_for_not_giving_a_lower_recommendation</th>\n",
       "      <th>c_comments_and_feedback_to_the_authors</th>\n",
       "      <th>c_consent_to_archive</th>\n",
       "      <th>c_Reviewer expertise</th>\n",
       "      <th>c_Review (Strengths/Weaknesses)</th>\n",
       "      <th>c_final_decision</th>\n",
       "      <th>c_content_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>https://openreview.net/forum?id=ryjw_eAaZ</td>\n",
       "      <td>--</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>A principled approach for structure learning o...</td>\n",
       "      <td>Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...</td>\n",
       "      <td>unsupervised learning,structure learning,deep ...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REVIEW title:\\nThere is a major technical flaw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>https://openreview.net/forum?id=ryjw_eAaZ</td>\n",
       "      <td>--</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>A principled approach for structure learning o...</td>\n",
       "      <td>Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...</td>\n",
       "      <td>unsupervised learning,structure learning,deep ...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REVIEW title:\\nInteresting unsupervised struct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>https://openreview.net/forum?id=ryjw_eAaZ</td>\n",
       "      <td>--</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>A principled approach for structure learning o...</td>\n",
       "      <td>Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...</td>\n",
       "      <td>unsupervised learning,structure learning,deep ...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REVIEW title:\\nPromising method, inconclusive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>https://openreview.net/forum?id=ryjw_eAaZ</td>\n",
       "      <td>--</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>A principled approach for structure learning o...</td>\n",
       "      <td>Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...</td>\n",
       "      <td>unsupervised learning,structure learning,deep ...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>REVIEW decision:\\nReject\\nREVIEW title:\\nICLR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rye7IMbAZ</td>\n",
       "      <td>Explicit Induction Bias for Transfer Learning...</td>\n",
       "      <td>https://openreview.net/forum?id=rye7IMbAZ</td>\n",
       "      <td>--</td>\n",
       "      <td>In inductive transfer learning, fine-tuning pr...</td>\n",
       "      <td>In inductive transfer learning, fine-tuning pr...</td>\n",
       "      <td>Xuhong LI,Yves GRANDVALET,Franck DAVOINE</td>\n",
       "      <td>transfer Learning,convolutional networks,fine-...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REVIEW title:\\nwell written, needs more compar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     b_forum                                            b_title  \\\n",
       "1  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "2  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "3  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "4  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "6  rye7IMbAZ   Explicit Induction Bias for Transfer Learning...   \n",
       "\n",
       "                                       b_url b_pub_date  \\\n",
       "1  https://openreview.net/forum?id=ryjw_eAaZ         --   \n",
       "2  https://openreview.net/forum?id=ryjw_eAaZ         --   \n",
       "3  https://openreview.net/forum?id=ryjw_eAaZ         --   \n",
       "4  https://openreview.net/forum?id=ryjw_eAaZ         --   \n",
       "6  https://openreview.net/forum?id=rye7IMbAZ         --   \n",
       "\n",
       "                                          b_abstract  \\\n",
       "1  We introduce an unsupervised structure learnin...   \n",
       "2  We introduce an unsupervised structure learnin...   \n",
       "3  We introduce an unsupervised structure learnin...   \n",
       "4  We introduce an unsupervised structure learnin...   \n",
       "6  In inductive transfer learning, fine-tuning pr...   \n",
       "\n",
       "                                             b_TL;DR  \\\n",
       "1  A principled approach for structure learning o...   \n",
       "2  A principled approach for structure learning o...   \n",
       "3  A principled approach for structure learning o...   \n",
       "4  A principled approach for structure learning o...   \n",
       "6  In inductive transfer learning, fine-tuning pr...   \n",
       "\n",
       "                                           b_authors  \\\n",
       "1  Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...   \n",
       "2  Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...   \n",
       "3  Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...   \n",
       "4  Raanan Y. Yehezkel Rohekar,Guy Koren,Shami Nis...   \n",
       "6           Xuhong LI,Yves GRANDVALET,Franck DAVOINE   \n",
       "\n",
       "                                          b_keywords b_venue b_venue_id  ...  \\\n",
       "1  unsupervised learning,structure learning,deep ...      --         --  ...   \n",
       "2  unsupervised learning,structure learning,deep ...      --         --  ...   \n",
       "3  unsupervised learning,structure learning,deep ...      --         --  ...   \n",
       "4  unsupervised learning,structure learning,deep ...      --         --  ...   \n",
       "6  transfer Learning,convolutional networks,fine-...      --         --  ...   \n",
       "\n",
       "   c_preliminary_rating c_suggested_changes  \\\n",
       "1                   NaN                 NaN   \n",
       "2                   NaN                 NaN   \n",
       "3                   NaN                 NaN   \n",
       "4                   NaN                 NaN   \n",
       "6                   NaN                 NaN   \n",
       "\n",
       "  c_reason_for_not_giving_a_higher_recommendation  \\\n",
       "1                                             NaN   \n",
       "2                                             NaN   \n",
       "3                                             NaN   \n",
       "4                                             NaN   \n",
       "6                                             NaN   \n",
       "\n",
       "  c_reason_for_not_giving_a_lower_recommendation  \\\n",
       "1                                            NaN   \n",
       "2                                            NaN   \n",
       "3                                            NaN   \n",
       "4                                            NaN   \n",
       "6                                            NaN   \n",
       "\n",
       "  c_comments_and_feedback_to_the_authors c_consent_to_archive  \\\n",
       "1                                    NaN                  NaN   \n",
       "2                                    NaN                  NaN   \n",
       "3                                    NaN                  NaN   \n",
       "4                                    NaN                  NaN   \n",
       "6                                    NaN                  NaN   \n",
       "\n",
       "   c_Reviewer expertise c_Review (Strengths/Weaknesses) c_final_decision  \\\n",
       "1                   NaN                             NaN              NaN   \n",
       "2                   NaN                             NaN              NaN   \n",
       "3                   NaN                             NaN              NaN   \n",
       "4                   NaN                             NaN         Rejected   \n",
       "6                   NaN                             NaN              NaN   \n",
       "\n",
       "                                       c_content_str  \n",
       "1  REVIEW title:\\nThere is a major technical flaw...  \n",
       "2  REVIEW title:\\nInteresting unsupervised struct...  \n",
       "3  REVIEW title:\\nPromising method, inconclusive ...  \n",
       "4  REVIEW decision:\\nReject\\nREVIEW title:\\nICLR ...  \n",
       "6  REVIEW title:\\nwell written, needs more compar...  \n",
       "\n",
       "[5 rows x 192 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去除review中的reference\n",
    "df_reviews_handle[\"c_content_str\"] = df_reviews_handle[\"c_content_str\"].apply(lambda x: re.sub(regex, \"\", x))\n",
    "df_reviews_handle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f7f7305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW title:\n",
      "Very interesting work and the proposed approach is well explained. The experimental section could be improved.\n",
      "REVIEW rating:\n",
      "8: Top 50% of accepted papers, clear accept\n",
      "REVIEW review:\n",
      "Summary:\n",
      "The manuscript extends the Neural Expectation Maximization framework by integrating an interaction function that allows asymmetric pairwise effects between objects. The network is demonstrated to learn compositional object representations which group together pixels, optimizing a predictive coding objective. The effectiveness of the approach is demonstrated on bouncing balls sequences and gameplay videos from Space Invaders. The proposed R-NEM model generalizes\n",
      "\n",
      "Review:\n",
      "Very interesting work and the proposed approach is well explained. The experimental section could be improved.\n",
      "I have a few questions/comments:\n",
      "1) Some limitations could have been discussed, e.g. how would the model perform on sequences involving more complicated deformations of objects than in the Space Invaders experiment? As you always take the first frame of the 4-frame stacks in the data set, do the objects deform at all?\n",
      "2) It would have been interesting to vary K, e.g. study the behaviour for K in {1,5,10,25,50}. In Space Invaders the model would probably really group together separate objects. What happens if you train with K=8 on sequences of 4 balls and then run on 8-ball sequences instead of providing (approximately) the right number of components both at training and test time (in the extrapolation experiment).\n",
      "3) One work that should be mentioned in the related work section is Michalski et al. (2014), which also uses noise and predictive coding to model sequences of bouncing balls and NORBvideos. Their model uses a factorization that also discovers relations between components of the frames, but in contrast to R-NEM the components overlap.\n",
      "4) A quantitative evaluation of the bouncing balls with curtain and Space Invaders experiments would be useful for comparison.\n",
      "5) I think the hyperparameters of the RNN and LSTM are missing from the manuscript. Did you perform any hyperparameter optimization on these models?\n",
      "6) Stronger baselines would improve the experimental section, maybe Seo et al (2016). Alternatively, you could train the model on Moving MNIST (Srivastava et al., 2015) and compare with other published results.\n",
      "\n",
      "I would consider increasing the score, if at least some of the above points are sufficiently addressed.\n",
      "\n",
      "REVIEW confidence:\n",
      "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n"
     ]
    }
   ],
   "source": [
    "# 再次查看之前的那条review，可见参考文献部分被剔除了\n",
    "print(df_reviews_handle[\"c_content_str\"].loc[39])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8d9566",
   "metadata": {},
   "source": [
    "### IV. 将可疑换行符转换为单换行符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2af7762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"REVIEW title:\\nThere is a major technical flaw in this paper. And some experiment settings are not convincing.\\nREVIEW rating:\\n4: Ok but not good enough - rejection\\nREVIEW review:\\nThe paper proposes an unsupervised structure learning method for deep neural networks. It first constructs a fully visible DAG by learning from data, and decomposes variables into autonomous sets. Then latent variables are introduced and stochastic inverse is generated. Later a deep neural network structure is constructed based on the discriminative graph. Both the problem considered in the paper and the proposed method look interesting. The resulting structure seems nice.\\nHowever, the reviewer indeed finds a major technical flaw in the paper. The foundation of the proposed method is on preserving the conditional dependencies in graph G. And each step mentioned in the paper, as it claims, can preserve all the conditional dependencies. However, in section 2.2, it seems that the stochastic inverse cannot. In Fig. 3(b), A and B are no longer dependent conditioned on {C,D,E} due to the v-structure induced in node H_A and H_B. Also in Fig. 3(c), if the reviewer understands correctly, the bidirectional edge between H_A and H_B is equivalent to H_A <- h -> H_B, which also induces a v-structure, blocking the dependency between A and B. Therefore, the very foundation of the proposed method is shattered. And the reviewer requests an explicit explanation of this issue.\\nBesides that, the reviewer also finds unfair comparisons in the experiments.\\n1. In section 5.1, although the authors show that the learned structure achieves 99.04%-99.07% compared with 98.4%-98.75% for fully connected layers, the comparisons are made by keeping the number of parameters similar in both cases. The comparisons are reasonable but not very convincing. Observing that the learned structures would be much sparser than the fully connected ones, it means that the number of neurons in the fully connected network is significantly smaller. Did the authors compare with fully connected network with similar number of neurons? In such case, which one is better? (Having fewer parameters is a plus, but in terms of accuracy the number of neurons really matters for fair comparison. In practice, we definitely would not use that small number of neurons in fully connected layers.)\\n2. In section 5.2, it is interesting to observe that using features from conv10 is better than that from last dense layer. But it is not a fair comparison with vanilla network. In vanilla VGG-16-D, there are 3 more conv layers and 3 more fully connected layers. If you find that taking features from conv10 is good for the learned structure, then maybe it will also be good by taking features from conv10 and then apply 2-3 fully-connected layers directly (The proposed structure learning is not comparable to convolutional layers, and what it should really compare to is fully-connected layers.) In such case, which one is better? \\nSecondly, VGG-16 is a large network designed for ImageNet data. For small dataset such as CIFAR10 and CIFAR100, it is really overkilled. That's maybe the reason why taking the output of shallow layers could achieve pretty good results.\\n3. In Fig. 6, again, comparing the learned structure with fully-connected network by keeping parameters to be similar and resulting in large difference of the number of neurons is unfair from my point of view.\\nFurthermore, all the comparisons are made with respect to fully-connected network or vanilla CNNs. No other structure learning methods are compared with. Reasonable baseline methods should be included.\\nIn conclusion, due to the above issues both in method and experiments, the reviewer thinks that this paper is not ready for publication.\\nREVIEW confidence:\\n4: The reviewer is confident but not absolutely certain that the evaluation is correct\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将\\n\\n\\n以及\\n\\n转为\\n\n",
    "# 去掉各种疑似\\\\n\n",
    "regex_3n = re.compile(r\"\\n\\n\\n\", flags=(re.S))\n",
    "regex_spn = re.compile(r\"\\n \\n\", flags=(re.S))\n",
    "regex_sln = re.compile(r\"\\\\n\", flags=(re.S))\n",
    "regex_2n = re.compile(r\"\\n\\n\", flags=(re.S))\n",
    "\n",
    "regexs_n = {\n",
    "    \"regex_3n\": regex_3n,\n",
    "    \"regex_spn\": regex_spn,\n",
    "    \"regex_sln\": regex_sln,\n",
    "    \"regex_2n\": regex_2n\n",
    "}\n",
    "def replace_1n(content, regexs=regexs_n):\n",
    "    content = re.sub(regexs[\"regex_3n\"], \"\\n\", content)\n",
    "    content = re.sub(regexs[\"regex_spn\"], \"\\n\", content)\n",
    "    content = re.sub(regexs[\"regex_sln\"], \"\\n\", content)\n",
    "    content = re.sub(regexs[\"regex_2n\"], \"\\n\", content)\n",
    "    content = re.sub(regexs[\"regex_spn\"], \"\\n\", content)\n",
    "    content = re.sub(regexs[\"regex_2n\"], \"\\n\", content)\n",
    "    return content\n",
    "\n",
    "df_reviews_handle[\"c_content_str\"] = df_reviews_handle[\"c_content_str\"].apply(lambda x: replace_1n(x))\n",
    "df_reviews_handle[\"c_content_str\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b739b5d8",
   "metadata": {},
   "source": [
    "### V. 为review划分大体类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "483a5433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Reviewer', 'Program_Chair', 'Area_Chair'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review类别大体分为3类：Reviewer、Area_Chair、Program_Chair\n",
    "# 根据r_signatures_class将review大体划分为该三大类\n",
    "# 后续可根据这3类信息对单条paper的多个review顺序进行编排\n",
    "df_reviews_handle[\"r_signatures_class\"] = [\"Reviewer\"] * df_reviews_handle.shape[0]\n",
    "df_reviews_handle.loc[df_reviews_handle[\"r_signatures\"].str.contains(\"(A|a)rea\"), \"r_signatures_class\"] = \"Area_Chair\"\n",
    "df_reviews_handle.loc[df_reviews_handle[\"r_signatures\"].str.contains(\"Program*\"), \"r_signatures_class\"] = \"Program_Chair\"\n",
    "df_reviews_handle[\"r_signatures_class\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba47084f",
   "metadata": {},
   "source": [
    "### VI. 取出后续训练真正会使用到的字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d49389a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['b_forum', 'b_title', 'b_url', 'b_pub_date', 'b_abstract', 'b_TL;DR',\n",
       "       'b_authors', 'b_keywords', 'b_venue', 'b_venue_id',\n",
       "       ...\n",
       "       'c_suggested_changes',\n",
       "       'c_reason_for_not_giving_a_higher_recommendation',\n",
       "       'c_reason_for_not_giving_a_lower_recommendation',\n",
       "       'c_comments_and_feedback_to_the_authors', 'c_consent_to_archive',\n",
       "       'c_Reviewer expertise', 'c_Review (Strengths/Weaknesses)',\n",
       "       'c_final_decision', 'c_content_str', 'r_signatures_class'],\n",
       "      dtype='object', length=193)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看现有字段，存在诸多冗余项\n",
    "df_reviews_handle.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "947654e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b_forum</th>\n",
       "      <th>b_title</th>\n",
       "      <th>b_abstract</th>\n",
       "      <th>c_content_str</th>\n",
       "      <th>r_signatures_class</th>\n",
       "      <th>c_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW title:\\nThere is a major technical flaw...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>There is a major technical flaw in this paper....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW title:\\nInteresting unsupervised struct...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>Interesting unsupervised structure learning al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW title:\\nPromising method, inconclusive ...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>Promising method, inconclusive results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW decision:\\nReject\\nREVIEW title:\\nICLR ...</td>\n",
       "      <td>Program_Chair</td>\n",
       "      <td>ICLR 2018 Conference Acceptance Decision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rye7IMbAZ</td>\n",
       "      <td>Explicit Induction Bias for Transfer Learning...</td>\n",
       "      <td>In inductive transfer learning, fine-tuning pr...</td>\n",
       "      <td>REVIEW title:\\nwell written, needs more compar...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>well written, needs more comparisons/analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25462</th>\n",
       "      <td>qkDCSV-RMt</td>\n",
       "      <td>Spectral Clustering Identifies High-risk Opioi...</td>\n",
       "      <td>National opioid prescribing guidelines and rel...</td>\n",
       "      <td>REVIEW title:\\nReview of paper 1\\nREVIEW revie...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>Review of paper 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25464</th>\n",
       "      <td>N0qlvDjnEv</td>\n",
       "      <td>Risk-Based Ring Vaccination: A Strategy for Pa...</td>\n",
       "      <td>Throughout an infectious disease crisis, resou...</td>\n",
       "      <td>REVIEW title:\\nRisk-based ring vaccination app...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>Risk-based ring vaccination appears promising....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25465</th>\n",
       "      <td>N0qlvDjnEv</td>\n",
       "      <td>Risk-Based Ring Vaccination: A Strategy for Pa...</td>\n",
       "      <td>Throughout an infectious disease crisis, resou...</td>\n",
       "      <td>REVIEW title:\\nThis paper proposed a risk-base...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>This paper proposed a risk-based ring vaccinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25466</th>\n",
       "      <td>N0qlvDjnEv</td>\n",
       "      <td>Risk-Based Ring Vaccination: A Strategy for Pa...</td>\n",
       "      <td>Throughout an infectious disease crisis, resou...</td>\n",
       "      <td>REVIEW title:\\nReview of the paper on risk-bas...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>Review of the paper on risk-based rink vaccina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25467</th>\n",
       "      <td>N0qlvDjnEv</td>\n",
       "      <td>Risk-Based Ring Vaccination: A Strategy for Pa...</td>\n",
       "      <td>Throughout an infectious disease crisis, resou...</td>\n",
       "      <td>REVIEW title:\\nReview of risk-based ring vacci...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>Review of risk-based ring vaccination</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18456 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          b_forum                                            b_title  \\\n",
       "1       ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "2       ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "3       ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "4       ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "6       rye7IMbAZ   Explicit Induction Bias for Transfer Learning...   \n",
       "...           ...                                                ...   \n",
       "25462  qkDCSV-RMt  Spectral Clustering Identifies High-risk Opioi...   \n",
       "25464  N0qlvDjnEv  Risk-Based Ring Vaccination: A Strategy for Pa...   \n",
       "25465  N0qlvDjnEv  Risk-Based Ring Vaccination: A Strategy for Pa...   \n",
       "25466  N0qlvDjnEv  Risk-Based Ring Vaccination: A Strategy for Pa...   \n",
       "25467  N0qlvDjnEv  Risk-Based Ring Vaccination: A Strategy for Pa...   \n",
       "\n",
       "                                              b_abstract  \\\n",
       "1      We introduce an unsupervised structure learnin...   \n",
       "2      We introduce an unsupervised structure learnin...   \n",
       "3      We introduce an unsupervised structure learnin...   \n",
       "4      We introduce an unsupervised structure learnin...   \n",
       "6      In inductive transfer learning, fine-tuning pr...   \n",
       "...                                                  ...   \n",
       "25462  National opioid prescribing guidelines and rel...   \n",
       "25464  Throughout an infectious disease crisis, resou...   \n",
       "25465  Throughout an infectious disease crisis, resou...   \n",
       "25466  Throughout an infectious disease crisis, resou...   \n",
       "25467  Throughout an infectious disease crisis, resou...   \n",
       "\n",
       "                                           c_content_str r_signatures_class  \\\n",
       "1      REVIEW title:\\nThere is a major technical flaw...           Reviewer   \n",
       "2      REVIEW title:\\nInteresting unsupervised struct...           Reviewer   \n",
       "3      REVIEW title:\\nPromising method, inconclusive ...           Reviewer   \n",
       "4      REVIEW decision:\\nReject\\nREVIEW title:\\nICLR ...      Program_Chair   \n",
       "6      REVIEW title:\\nwell written, needs more compar...           Reviewer   \n",
       "...                                                  ...                ...   \n",
       "25462  REVIEW title:\\nReview of paper 1\\nREVIEW revie...           Reviewer   \n",
       "25464  REVIEW title:\\nRisk-based ring vaccination app...           Reviewer   \n",
       "25465  REVIEW title:\\nThis paper proposed a risk-base...           Reviewer   \n",
       "25466  REVIEW title:\\nReview of the paper on risk-bas...           Reviewer   \n",
       "25467  REVIEW title:\\nReview of risk-based ring vacci...           Reviewer   \n",
       "\n",
       "                                                 c_title  \n",
       "1      There is a major technical flaw in this paper....  \n",
       "2      Interesting unsupervised structure learning al...  \n",
       "3                 Promising method, inconclusive results  \n",
       "4               ICLR 2018 Conference Acceptance Decision  \n",
       "6          well written, needs more comparisons/analysis  \n",
       "...                                                  ...  \n",
       "25462                                  Review of paper 1  \n",
       "25464  Risk-based ring vaccination appears promising....  \n",
       "25465  This paper proposed a risk-based ring vaccinat...  \n",
       "25466  Review of the paper on risk-based rink vaccina...  \n",
       "25467              Review of risk-based ring vaccination  \n",
       "\n",
       "[18456 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取出真正可能需要使用到的字段\n",
    "# b_forum作为id用于与paper进行匹配\n",
    "# b_title为和b_abstract为论文的信息，后续可用于填补上述paper的title和abstract缺失的情况\n",
    "# c_content_str为review正文\n",
    "# r_signatures_class为review的大类用于编排多轮对话中review的顺序，Reviewer靠前、Area_Chair为次、Program_Chair靠后\n",
    "# c_title是review title，用以进一步判断review是否应当放后面，因为通常起决定性的review包含有字符串“Decision”\n",
    "df_reviews_msg = df_reviews_handle[[\"b_forum\", \"b_title\", \"b_abstract\", \"c_content_str\", \"r_signatures_class\", \"c_title\"]]\n",
    "df_reviews_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7675247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b_forum</th>\n",
       "      <th>b_title</th>\n",
       "      <th>b_abstract</th>\n",
       "      <th>c_content_str</th>\n",
       "      <th>r_signatures_class</th>\n",
       "      <th>c_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW title:\\nThere is a major technical flaw...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>There is a major technical flaw in this paper....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW title:\\nInteresting unsupervised struct...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>Interesting unsupervised structure learning al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW title:\\nPromising method, inconclusive ...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>Promising method, inconclusive results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW decision:\\nReject\\nREVIEW title:\\nICLR ...</td>\n",
       "      <td>Program_Chair</td>\n",
       "      <td>ICLR 2018 Conference Acceptance Decision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rye7IMbAZ</td>\n",
       "      <td>Explicit Induction Bias for Transfer Learning...</td>\n",
       "      <td>In inductive transfer learning, fine-tuning pr...</td>\n",
       "      <td>REVIEW title:\\nwell written, needs more compar...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>well written, needs more comparisons/analysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     b_forum                                            b_title  \\\n",
       "1  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "2  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "3  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "4  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "6  rye7IMbAZ   Explicit Induction Bias for Transfer Learning...   \n",
       "\n",
       "                                          b_abstract  \\\n",
       "1  We introduce an unsupervised structure learnin...   \n",
       "2  We introduce an unsupervised structure learnin...   \n",
       "3  We introduce an unsupervised structure learnin...   \n",
       "4  We introduce an unsupervised structure learnin...   \n",
       "6  In inductive transfer learning, fine-tuning pr...   \n",
       "\n",
       "                                       c_content_str r_signatures_class  \\\n",
       "1  REVIEW title:\\nThere is a major technical flaw...           Reviewer   \n",
       "2  REVIEW title:\\nInteresting unsupervised struct...           Reviewer   \n",
       "3  REVIEW title:\\nPromising method, inconclusive ...           Reviewer   \n",
       "4  REVIEW decision:\\nReject\\nREVIEW title:\\nICLR ...      Program_Chair   \n",
       "6  REVIEW title:\\nwell written, needs more compar...           Reviewer   \n",
       "\n",
       "                                             c_title  \n",
       "1  There is a major technical flaw in this paper....  \n",
       "2  Interesting unsupervised structure learning al...  \n",
       "3             Promising method, inconclusive results  \n",
       "4           ICLR 2018 Conference Acceptance Decision  \n",
       "6      well written, needs more comparisons/analysis  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据中仍存在缺失值与双横杠“--”，需要将它们处理成空字符串\n",
    "# 先将“--”处理成缺失值，再统一将缺失值替换为空字符串\n",
    "df_reviews_msg = df_reviews_msg.replace(\"--\", pd.NA).fillna(\"\")\n",
    "df_reviews_msg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33db0258",
   "metadata": {},
   "source": [
    "### VII. 编排单条paper的多个review的顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb9285c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b_forum</th>\n",
       "      <th>b_title</th>\n",
       "      <th>b_abstract</th>\n",
       "      <th>c_content_str</th>\n",
       "      <th>r_signatures_class</th>\n",
       "      <th>c_title</th>\n",
       "      <th>r_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW title:\\nThere is a major technical flaw...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>There is a major technical flaw in this paper....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW title:\\nInteresting unsupervised struct...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>Interesting unsupervised structure learning al...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW title:\\nPromising method, inconclusive ...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>Promising method, inconclusive results</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW decision:\\nReject\\nREVIEW title:\\nICLR ...</td>\n",
       "      <td>Program_Chair</td>\n",
       "      <td>ICLR 2018 Conference Acceptance Decision</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rye7IMbAZ</td>\n",
       "      <td>Explicit Induction Bias for Transfer Learning...</td>\n",
       "      <td>In inductive transfer learning, fine-tuning pr...</td>\n",
       "      <td>REVIEW title:\\nwell written, needs more compar...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>well written, needs more comparisons/analysis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     b_forum                                            b_title  \\\n",
       "1  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "2  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "3  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "4  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "6  rye7IMbAZ   Explicit Induction Bias for Transfer Learning...   \n",
       "\n",
       "                                          b_abstract  \\\n",
       "1  We introduce an unsupervised structure learnin...   \n",
       "2  We introduce an unsupervised structure learnin...   \n",
       "3  We introduce an unsupervised structure learnin...   \n",
       "4  We introduce an unsupervised structure learnin...   \n",
       "6  In inductive transfer learning, fine-tuning pr...   \n",
       "\n",
       "                                       c_content_str r_signatures_class  \\\n",
       "1  REVIEW title:\\nThere is a major technical flaw...           Reviewer   \n",
       "2  REVIEW title:\\nInteresting unsupervised struct...           Reviewer   \n",
       "3  REVIEW title:\\nPromising method, inconclusive ...           Reviewer   \n",
       "4  REVIEW decision:\\nReject\\nREVIEW title:\\nICLR ...      Program_Chair   \n",
       "6  REVIEW title:\\nwell written, needs more compar...           Reviewer   \n",
       "\n",
       "                                             c_title  r_order  \n",
       "1  There is a major technical flaw in this paper....        1  \n",
       "2  Interesting unsupervised structure learning al...        2  \n",
       "3             Promising method, inconclusive results        3  \n",
       "4           ICLR 2018 Conference Acceptance Decision      151  \n",
       "6      well written, needs more comparisons/analysis        1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 编排顺序\n",
    "# 根据r_signatures_class，Reviewer靠前，Area_Chair其次，Program_Chair最后\n",
    "# 如果有数个Program_Chair，则c_title带Decision的就放最后，否则就随机\n",
    "\n",
    "class sorter:\n",
    "    def __init__(self):\n",
    "        self.forum_dict = {}\n",
    "        \n",
    "    def sort_review(self, row):\n",
    "        self.forum_dict[row[\"b_forum\"]] = self.forum_dict.get(row[\"b_forum\"], \n",
    "                                                              {\"reviewer_count\": 0, \n",
    "                                                             \"area_chair_count\": 50, \n",
    "                                                             \"program_chair_basic_count\": 100, \n",
    "                                                             \"program_chair_decision_count\": 150})\n",
    "        if row[\"r_signatures_class\"] == \"Reviewer\":\n",
    "            self.forum_dict[row[\"b_forum\"]][\"reviewer_count\"] = self.forum_dict[row[\"b_forum\"]][\"reviewer_count\"] + 1\n",
    "            return self.forum_dict[row[\"b_forum\"]][\"reviewer_count\"]\n",
    "        elif row[\"r_signatures_class\"] == \"Area_Chair\":\n",
    "            self.forum_dict[row[\"b_forum\"]][\"area_chair_count\"] = self.forum_dict[row[\"b_forum\"]][\"area_chair_count\"] + 1\n",
    "            return self.forum_dict[row[\"b_forum\"]][\"area_chair_count\"]\n",
    "        else:\n",
    "            if \"Decision\" in row[\"c_title\"]:\n",
    "                self.forum_dict[row[\"b_forum\"]][\"program_chair_decision_count\"] = self.forum_dict[row[\"b_forum\"]][\"program_chair_decision_count\"] + 1\n",
    "                return self.forum_dict[row[\"b_forum\"]][\"program_chair_decision_count\"]\n",
    "            else:\n",
    "                self.forum_dict[row[\"b_forum\"]][\"program_chair_basic_count\"] = self.forum_dict[row[\"b_forum\"]][\"program_chair_basic_count\"] + 1\n",
    "                return self.forum_dict[row[\"b_forum\"]][\"program_chair_basic_count\"]\n",
    "srt = sorter()\n",
    "df_reviews_msg[\"r_order\"] = df_reviews_msg.apply(lambda x: srt.sort_review(x), axis=1)\n",
    "\n",
    "df_reviews_msg.head()\n",
    "\n",
    "# 后续如果要做多轮对话的话，根据r_order的大小顺序由小至大进行编排即可"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5430c45b",
   "metadata": {},
   "source": [
    "### VIII. 检查review侧提供的paper title信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "934cb433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Unsupervised Deep Structure Learning by Recurs...\n",
       "2    Unsupervised Deep Structure Learning by Recurs...\n",
       "3    Unsupervised Deep Structure Learning by Recurs...\n",
       "4    Unsupervised Deep Structure Learning by Recurs...\n",
       "6     Explicit Induction Bias for Transfer Learning...\n",
       "Name: b_title_new, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查review侧提供的paper信息（title、abstract）是否异常\n",
    "# 后续将使用review侧提供的paper信息来填补paper侧的缺失信息\n",
    "\n",
    "# 将可疑换行符替换为单换行符\n",
    "df_reviews_msg[\"b_title_new\"] = df_reviews_msg[\"b_title\"].apply(lambda x: replace_1n(x))\n",
    "df_reviews_msg[\"b_title_new\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c076a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223       1\n",
       "224       1\n",
       "225       1\n",
       "226       1\n",
       "227       1\n",
       "         ..\n",
       "11546    23\n",
       "23751    25\n",
       "23750    25\n",
       "23753    25\n",
       "23752    25\n",
       "Name: b_title_count, Length: 18456, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计title单词数\n",
    "# 发现存在单词数为1的情况\n",
    "# 实际上是正常现象，有的论文确实就是以技术名称为论文标题，所以是有可能仅有1个单词的\n",
    "df_reviews_msg[\"b_title_count\"] = df_reviews_msg[\"b_title_new\"].map(lambda x: len(x.split()) if pd.notnull(x) else 0)\n",
    "df_reviews_msg[\"b_title_count\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f72b3f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10     5.0\n",
       "0.25     6.0\n",
       "0.50     8.0\n",
       "0.75    10.0\n",
       "0.90    12.0\n",
       "0.99    15.0\n",
       "1.00    25.0\n",
       "Name: b_title_count, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看分位数情况\n",
    "# 整体比较正常，暂未发现无内容和异常情况\n",
    "df_reviews_msg[\"b_title_count\"].quantile(q=[0.1,0.25,0.5,0.75,0.9,0.99,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ddd2e",
   "metadata": {},
   "source": [
    "### IX. 检查review侧提供的paper abstract信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bfef4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    We introduce an unsupervised structure learnin...\n",
       "2    We introduce an unsupervised structure learnin...\n",
       "3    We introduce an unsupervised structure learnin...\n",
       "4    We introduce an unsupervised structure learnin...\n",
       "6    In inductive transfer learning, fine-tuning pr...\n",
       "Name: b_abstract_new, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查review侧提供的paper信息（title、abstract）是否异常\n",
    "# 后续将使用review侧提供的paper信息来填补paper侧的缺失信息\n",
    "\n",
    "# 将可疑换行符替换为单换行符\n",
    "df_reviews_msg[\"b_abstract_new\"] = df_reviews_msg[\"b_abstract\"].apply(lambda x: replace_1n(x))\n",
    "df_reviews_msg[\"b_abstract_new\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9046bf10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19216     33\n",
       "1985      37\n",
       "1983      37\n",
       "1982      37\n",
       "1984      37\n",
       "        ... \n",
       "11374    455\n",
       "11371    455\n",
       "19785    552\n",
       "19787    552\n",
       "19786    552\n",
       "Name: b_abstract_count, Length: 18456, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计abstarct单词数\n",
    "# 发现存在单词数为0的情况\n",
    "# 后续可以与paper侧互补，若实在不存在abstarct则将该条paper剔除\n",
    "df_reviews_msg[\"b_abstract_count\"] = df_reviews_msg[\"b_abstract_new\"].map(lambda x: len(x.split()) if pd.notnull(x) else 0)\n",
    "df_reviews_msg[\"b_abstract_count\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df068f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01     72.0\n",
       "0.10    116.0\n",
       "0.25    142.0\n",
       "0.50    169.0\n",
       "0.75    199.0\n",
       "0.90    229.0\n",
       "0.99    304.0\n",
       "1.00    552.0\n",
       "Name: b_abstract_count, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看分位数情况\n",
    "# 整体比较正常\n",
    "df_reviews_msg[\"b_abstract_count\"].quantile(q=[0.01, 0.1,0.25,0.5,0.75,0.9,0.99,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19164e52",
   "metadata": {},
   "source": [
    "# 三、整合paper与review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a287845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除无用变量，释放内存占用\n",
    "del df_sci, df_reviews, df_reviews_rest_subtitle, df_reviews_handle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfb500a",
   "metadata": {},
   "source": [
    "## 1. paper侧与review侧信息（title、abstract）互补"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35326185",
   "metadata": {},
   "source": [
    "### I. 将paper和review根据forum进行merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eaf1a2b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'authors', 'pub_date', 'abstract', 'sections', 'references',\n",
       "       'figures', 'formulas', 'doi', 'forum', 'main', 'main_count',\n",
       "       'title_new', 'title_new_count', 'abstract_new', 'abstract_new_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看paper的字段\n",
    "df_sci_handle.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70462b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['b_forum', 'b_title', 'b_abstract', 'c_content_str',\n",
       "       'r_signatures_class', 'c_title', 'r_order', 'b_title_new',\n",
       "       'b_title_count', 'b_abstract_new', 'b_abstract_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看review的字段\n",
    "df_reviews_msg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3ac07cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b_forum</th>\n",
       "      <th>b_title_new</th>\n",
       "      <th>b_abstract_new</th>\n",
       "      <th>c_content_str</th>\n",
       "      <th>r_signatures_class</th>\n",
       "      <th>r_order</th>\n",
       "      <th>b_title_count</th>\n",
       "      <th>b_abstract_count</th>\n",
       "      <th>forum</th>\n",
       "      <th>title_new</th>\n",
       "      <th>abstract_new</th>\n",
       "      <th>main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW title:\\nThere is a major technical flaw...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>230</td>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>UNSUPERVISED DEEP STRUCTURE LEARNING BY RECURS...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>PAPER INTRODUCTION:\\nOver the last decade, dee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW title:\\nInteresting unsupervised struct...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>230</td>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>UNSUPERVISED DEEP STRUCTURE LEARNING BY RECURS...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>PAPER INTRODUCTION:\\nOver the last decade, dee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW title:\\nPromising method, inconclusive ...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>230</td>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>UNSUPERVISED DEEP STRUCTURE LEARNING BY RECURS...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>PAPER INTRODUCTION:\\nOver the last decade, dee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>REVIEW decision:\\nReject\\nREVIEW title:\\nICLR ...</td>\n",
       "      <td>Program_Chair</td>\n",
       "      <td>151</td>\n",
       "      <td>8</td>\n",
       "      <td>230</td>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>UNSUPERVISED DEEP STRUCTURE LEARNING BY RECURS...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>PAPER INTRODUCTION:\\nOver the last decade, dee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rye7IMbAZ</td>\n",
       "      <td>Explicit Induction Bias for Transfer Learning...</td>\n",
       "      <td>In inductive transfer learning, fine-tuning pr...</td>\n",
       "      <td>REVIEW title:\\nwell written, needs more compar...</td>\n",
       "      <td>Reviewer</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>138</td>\n",
       "      <td>rye7IMbAZ</td>\n",
       "      <td>EXPLICIT INDUCTION BIAS FOR TRANSFER LEARN-ING...</td>\n",
       "      <td>In inductive transfer learning, fine-tuning pr...</td>\n",
       "      <td>PAPER INTRODUCTION:\\nIt is now well known that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     b_forum                                        b_title_new  \\\n",
       "0  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "1  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "2  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "3  ryjw_eAaZ  Unsupervised Deep Structure Learning by Recurs...   \n",
       "4  rye7IMbAZ   Explicit Induction Bias for Transfer Learning...   \n",
       "\n",
       "                                      b_abstract_new  \\\n",
       "0  We introduce an unsupervised structure learnin...   \n",
       "1  We introduce an unsupervised structure learnin...   \n",
       "2  We introduce an unsupervised structure learnin...   \n",
       "3  We introduce an unsupervised structure learnin...   \n",
       "4  In inductive transfer learning, fine-tuning pr...   \n",
       "\n",
       "                                       c_content_str r_signatures_class  \\\n",
       "0  REVIEW title:\\nThere is a major technical flaw...           Reviewer   \n",
       "1  REVIEW title:\\nInteresting unsupervised struct...           Reviewer   \n",
       "2  REVIEW title:\\nPromising method, inconclusive ...           Reviewer   \n",
       "3  REVIEW decision:\\nReject\\nREVIEW title:\\nICLR ...      Program_Chair   \n",
       "4  REVIEW title:\\nwell written, needs more compar...           Reviewer   \n",
       "\n",
       "   r_order  b_title_count  b_abstract_count      forum  \\\n",
       "0        1              8               230  ryjw_eAaZ   \n",
       "1        2              8               230  ryjw_eAaZ   \n",
       "2        3              8               230  ryjw_eAaZ   \n",
       "3      151              8               230  ryjw_eAaZ   \n",
       "4        1              9               138  rye7IMbAZ   \n",
       "\n",
       "                                           title_new  \\\n",
       "0  UNSUPERVISED DEEP STRUCTURE LEARNING BY RECURS...   \n",
       "1  UNSUPERVISED DEEP STRUCTURE LEARNING BY RECURS...   \n",
       "2  UNSUPERVISED DEEP STRUCTURE LEARNING BY RECURS...   \n",
       "3  UNSUPERVISED DEEP STRUCTURE LEARNING BY RECURS...   \n",
       "4  EXPLICIT INDUCTION BIAS FOR TRANSFER LEARN-ING...   \n",
       "\n",
       "                                        abstract_new  \\\n",
       "0  We introduce an unsupervised structure learnin...   \n",
       "1  We introduce an unsupervised structure learnin...   \n",
       "2  We introduce an unsupervised structure learnin...   \n",
       "3  We introduce an unsupervised structure learnin...   \n",
       "4  In inductive transfer learning, fine-tuning pr...   \n",
       "\n",
       "                                                main  \n",
       "0  PAPER INTRODUCTION:\\nOver the last decade, dee...  \n",
       "1  PAPER INTRODUCTION:\\nOver the last decade, dee...  \n",
       "2  PAPER INTRODUCTION:\\nOver the last decade, dee...  \n",
       "3  PAPER INTRODUCTION:\\nOver the last decade, dee...  \n",
       "4  PAPER INTRODUCTION:\\nIt is now well known that...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = pd.merge(df_reviews_msg[[\"b_forum\",\"b_title_new\",\"b_abstract_new\",\"c_content_str\",\n",
    "                             \"r_signatures_class\",\"r_order\",\"b_title_count\",\n",
    "                             \"b_abstract_count\"]],\n",
    "                            df_sci_handle[[\"forum\",\"title_new\",\"abstract_new\",\"main\"]],\n",
    "                            how=\"left\",\n",
    "                            left_on=\"b_forum\",\n",
    "                            right_on=\"forum\")\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c2a9a0",
   "metadata": {},
   "source": [
    "### II. 信息互补"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91df0a1b",
   "metadata": {},
   "source": [
    "基于上述分析结果，可制定如下信息互补规则：\n",
    "1. title选取：因为review侧的title较为正常，以review侧的title为准。\n",
    "2. abstract选取：以review侧的abstract为准，如果review侧提供的abstract单词数大于总体的99分位数，那么可以查阅paper侧提供的abstract，如果paper侧存在abstract且字数小于review侧abstract，则选取paper侧abstract作为最终abstract，否则仍取review侧abstract。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "108571f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title互补\n",
    "df_merge[\"final_title\"] = df_merge[\"b_title_new\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57fcc509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        We introduce an unsupervised structure learnin...\n",
       "1        We introduce an unsupervised structure learnin...\n",
       "2        We introduce an unsupervised structure learnin...\n",
       "3        We introduce an unsupervised structure learnin...\n",
       "4        In inductive transfer learning, fine-tuning pr...\n",
       "                               ...                        \n",
       "18451    National opioid prescribing guidelines and rel...\n",
       "18452    Throughout an infectious disease crisis, resou...\n",
       "18453    Throughout an infectious disease crisis, resou...\n",
       "18454    Throughout an infectious disease crisis, resou...\n",
       "18455    Throughout an infectious disease crisis, resou...\n",
       "Name: final_abstract, Length: 18456, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# abstract互补\n",
    "abs99 = df_merge[\"b_abstract_count\"].quantile(q=0.99)\n",
    "\n",
    "def find_abs(row, th=abs99):\n",
    "    if row[\"b_abstract_count\"] > th:\n",
    "        if row[\"abstract_new\"] and pd.notnull(row[\"abstract_new\"]):\n",
    "            return row[\"abstract_new\"]\n",
    "        else:\n",
    "            return row[\"b_abstract_new\"]\n",
    "    elif row[\"b_abstract_count\"] == 0:\n",
    "        if row[\"abstract_new\"] and pd.notnull(row[\"abstract_new\"]):\n",
    "            return row[\"abstract_new\"]\n",
    "        else:\n",
    "            return \"\"\n",
    "    else:\n",
    "        return row[\"b_abstract_new\"]\n",
    "\n",
    "df_merge[\"final_abstract\"] = df_merge.apply(lambda x: find_abs(x), axis=1)\n",
    "df_merge[\"final_abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e09f3455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14382     33\n",
       "1500      37\n",
       "1498      37\n",
       "1497      37\n",
       "1499      37\n",
       "        ... \n",
       "8413     458\n",
       "10754    458\n",
       "10753    458\n",
       "8416     458\n",
       "8415     458\n",
       "Name: final_abstract, Length: 18456, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看互补后abstract的单词数，发现仍存在无信息项（单词数为0的情况）\n",
    "df_merge[\"final_abstract\"].map(lambda x: len(x.split()) if pd.notnull(x) else 0).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fb283b",
   "metadata": {},
   "source": [
    "### III. 去除无信息项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b068da06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18456 ==> 17881\n"
     ]
    }
   ],
   "source": [
    "# 去除无信息项\n",
    "df_merge_drop = df_merge.dropna(subset=[\"final_title\",\"final_abstract\",\"main\",\"c_content_str\"], how=\"any\")[[\"forum\",\"r_order\",\"c_content_str\",\"final_title\",\"final_abstract\",\"main\"]]\n",
    "print(\"{} ==> {}\".format(df_merge.shape[0], df_merge_drop.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056e22ed",
   "metadata": {},
   "source": [
    "## 2. 由补信息后的title、abstract、main拼接得到paper内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7c30145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAPER Title:\n",
      "Unsupervised Deep Structure Learning by Recursive Dependency Analysis\n",
      "PAPER Abstract:\n",
      "We introduce an unsupervised structure learning algorithm for deep, feed-forward, neural networks. We propose a new interpretation for depth and inter-layer connectivity where a hierarchy of independencies in the input distribution is encoded in the network structure. This results in structures allowing neurons to connect to neurons in any deeper layer skipping intermediate layers. Moreover, neurons in deeper layers encode low-order (small condition sets) independencies and have a wide scope of the input, whereas neurons in the first layers encode higher-order (larger condition sets) independencies and have a narrower scope. Thus, the depth of the network is automatically determined---equal to the maximal order of independence in the input distribution, which is the recursion-depth of the algorithm. The proposed algorithm constructs two main graphical models: 1) a generative latent graph (a deep belief network) learned from data and 2) a deep discriminative graph constructed from the generative latent graph. We prove that conditional dependencies between the nodes in the learned generative latent graph are preserved in the class-conditional discriminative graph. Finally, a deep neural network structure is constructed based on the discriminative graph. We demonstrate on image classification benchmarks that the algorithm replaces the deepest layers (convolutional and dense layers) of common convolutional networks, achieving high classification accuracy, while constructing significantly smaller structures. The proposed structure learning algorithm requires a small computational cost and runs efficiently on a standard desktop CPU.\n",
      "PAPER INTRODUCTION:\n",
      "Over the last decade, deep neural networks have proven their effectiveness in solving many challenging problems in various domains such as speech recognition (Graves & Schmidhuber, 2005), computer vision (Krizhevsky et al., 2012;Girshick et al., 2014;Simonyan & Zisserman, 2014; and machine translation (Collobert et al., 2011b). As compute resources became more available, large scale models having millions of parameters could be trained on massive volumes of data, to achieve state-of-the-art solutions for these high dimensionality problems. Building these models requires various design choices such as network topology, cost function, optimization technique, and the configuration of related hyper-parameters.\n",
      "In this paper, we focus on the design of network topology-structure learning. Generally, exploration of this design space is a time consuming iterative process that requires close supervision by a human expert. Many studies provide guidelines for design choices such as network depth (Simonyan & Zisserman, 2014), layer width (Zagoruyko & Komodakis, 2016), building blocks , and connectivity (He et al., 2016;Huang et al., 2016). Based on these guidelines, these studies propose several meta-architectures, trained on huge volumes of data. These were applied to other tasks by leveraging the representational power of their convolutional layers and fine-tuning their deepest layers for the task at hand Hinton et al., 2015;Long et al., 2015;. However, these meta-architecture may be unnecessarily large and require large computational power and memory for training and inference.\n",
      "The problem of model structure learning has been widely researched for many years in the probabilistic graphical models domain. Specifically, Bayesian networks for density estimation and causal discovery (Pearl, 2009;Spirtes et al., 2000). Two main approaches were studied: score-based (search-and-score) and constraint-based. Score-based approaches combine a scoring function, such as BDe (Cooper & Herskovits, 1992) and BIC (Ripley, 2007), with a strategy for searching through the space of structures, such as greedy equivalence search (Chickering, 2002). Adams et al. (2010) introduced an algorithm for sampling deep belief networks (generative model) and demonstrated its applicability to high-dimensional image datasets.\n",
      "Constraint-based approaches (Pearl, 2009;Spirtes et al., 2000) find the optimal structures in the large sample limit by testing conditional independence (CI) between pairs of variables. They are generally faster than score-based approaches (Yehezkel & Lerner, 2009) and have a well-defined stopping criterion (e.g., maximal order of conditional independence). However, these methods are sensitive to errors in the independence tests, especially in the case of high-order conditional-independence tests and small training sets.\n",
      "Motivated by these methods, we propose a new interpretation for depth and inter-layer connectivity in deep neural networks. We derive a structure learning algorithm such that a hierarchy of independencies in the input distribution is encoded in the network structure, where the first layers encode higher-order independencies than deeper layers. Thus, the number of layers is automatically determined. Moreover, a neuron in a layer is allowed to connect to neurons in deeper layers skipping intermediate layers. An example of a learned structure, for MNIST, is given in Figure 1.\n",
      "We describe our recursive algorithm in two steps. In Section 2 we describe a base case-a singlelayer structure learning. In Section 3 we describe multi-layer structure learning by applying the key concepts of the base case, recursively (proofs are provided in Appendix A). In Section 4 we discuss related work. We provide experimental results in Section 5, and conclude in Section 6.\n",
      "Preliminaries. Consider X = {X i } N i=1 a set of observed (input) random variables, H = {H j } K j=1\n",
      "a set of latent variables, and Y a class variable. Our algorithm constructs three graphical models and an auxiliary graph. Each variable is represented by a single node and a single edge may connect two distinct nodes. Graph G is a generative DAG defined over the observed and latent variables X ∪ H. Graph G Inv is called a stochastic inverse of G. Graph G D is a discriminative model defined over the observed, latent, and class variables X ∪ H ∪ Y . An auxiliary graph G X is defined over X (a CPDAG; an equivalence class of a Bayesian network) and is generated and maintained as an internal state of the algorithm. The parents set of a node X in G is denoted P a(X; G). The order of an independence relation is defined to be the condition set size. For example, if X 1 and X 2 are independent given X 3 and X 4 , denoted X 1 ⊥ ⊥ X 2 |{X 3 , X 4 }, then the independence order is two.\n",
      "output layer gather layer dense layer input layer conc atenate copy Figure 1: An example of a structure learned by our algorithm (classifying MNIST digits). Neurons in a layer may connect to neurons in any deeper layer. Depth is determined automatically. Each gather layer selects a subset of the input, where each input variable is gathered only once. A neural route, starting with a gather layer, passes through densely connected layers where it may split (copy) and merge (concatenate) with other routes in correspondence with the hierarchy of independencies identified by the algorithm. All routes merge into the final output layer (e.g., a softmax layer).\n",
      "PAPER SINGLE LAYER STRUCTURE LEARNING:\n",
      "We start by describing the key concepts of our approach using a simple scenario: learning the connectivity of a single-layer neural network.\n",
      "PAPER CONSTRUCTING A GENERATIVE GRAPH:\n",
      "Assume the input joint distribution p(X) complies with the following property.\n",
      "Assumption 1. The joint distribution p(X) is faithful to a DAG G over observed X and latent nodes H, where for all X ∈ X and H ∈ H, P a(X; G) ⊆ H and P a(H; G) ⊆ H\\H.\n",
      "p X; G = p X, H; G dH = p H N i=1 p X i P a(X i ; G) dH.\n",
      "(1)\n",
      "Note that the generative graphical model G can be described as a layered deep belief network where parents of a node in layer m can be in any deeper layer, indexes greater than m, and not restricted to the next layer m + 1. This differs from the common definition of deep belief networks (Hinton et al., 2006;Adams et al., 2010) where the parents are restricted to layer m + 1.\n",
      "It is desired to learn an efficient graph G having small sets of parents and a simple factorization of p(H) while maintaining high expressive power. We first construct an auxiliary graph, a CPDAG (Spirtes et al., 2000), G X over X (an equivalence class of a fully visible Bayesian network) encoding only marginal independencies 1 (empty condition sets) and then construct G such that it can mimic G X over X, denoted G X G (Pearl, 2009). That is, preserving all conditional dependencies of X in G X .\n",
      "The simplest connected DAG that encodes statistical independence is the v-structure, a structure with three nodes X 1 → X 3 ← X 2 in which X 1 and X 2 are marginally independent X 1 ⊥ ⊥ X 2 and conditionally dependent X 1 ⊥ ⊥X 2 |X 3 . In graphs encoding only marginal independencies, dependent nodes form a clique. We follow the procedure described by Yehezkel & Lerner (2009) and decompose X into autonomous sets (complying with the Markov property) where one set, denoted X D (descendants), is the common child of all other sets, denoted X A1 , . . . , X AK (ancestor sets). We select X D to be the set of nodes that have the lowest topological order in G X . Then, by removing X D from G X (temporarily for this step), the resulting K disjoint sets of nodes (corresponding to K disjoint substructures) form the K ancestor sets {X Ai } K i=1 . See an example in Figure 2. Next, G is initialized to an empty graph over X. Then, for each ancestor set X Ai a latent variable H i is introduced and assigned to be a common parent of the pair (X Ai , X D ). Thus,\n",
      "p X; G = K i=1   p H i X∈XA i p X H i   X ∈XD p X H dH.\n",
      "(2)\n",
      "Note that the parents of two ancestor sets are distinct, whereas the parents set of the descendant set is composed of all the latent variables.\n",
      "In the auxiliary graph G X , for each of the resulting v-structures (X Ai → X D ← X Aj ), a link between a parent and a child can be replaced by a common latent parent without introducing new independencies. For example, in Figure 2-[b], X A1 = {A}, X A2 = {B}, and X D = {C, D, E}.\n",
      "Adding a common latent parent (Figure 3-[a]) H A (or H B ) and removing all the edges from X A1 (or X A2 ) to X D preserves the conditional dependence A ⊥ ⊥ B|{C, D, E}.\n",
      "Algorithm 1 summarizes the procedure of constructing G having a single latent layer. Note that we do not claim to identify the presence of confounders and their inter-relations as in Elidan et al. (2001); Silva et al. (2006); Asbeh & Lerner (2016). Instead, we augment a fully observed Bayesian network with latent variables, while preserving conditional dependence.\n",
      "[a] \n",
      "C E D B A [b] C E D B A\n",
      ", X A1 = {A}, X A2 = {B}-disjoint if {C, D, E} is removed from the graph. [a] C E D B A HA HB [b] C E D B A HA HB [c] C E D B A HA HB [d] C E D B A HA HB Y Figure 3: [a] An example of a graph G (corresponding to G X in Figure 2-[b]). [b]\n",
      "A stochastic inverse generated by the algorithm presented by Stuhlmüller et al. (2013).\n",
      "[c] A stochastic inverse generated by our method where the graph is a projection of a latent structure. A dependency induced by a latent Q is described using a bi-directional edge\n",
      "H A ↔ H B . [d] A discriminative structure G D\n",
      "having a class node Y that provides an explaining away relation for\n",
      "H A ↔ H B .\n",
      "That is, the latent Q is replaced by an observed common child Y .\n",
      "PAPER CONSTRUCTING A STOCHASTIC INVERSE:\n",
      "It is important to note that G represents a generative distribution of X and is constructed in an unsupervised manner (class variable Y is ignored). Hence, we construct G Inv , a graphical model that preserves all conditional dependencies in G but has a different node ordering in which the observed variables, X, have the highest topological order (parentless)-a stochastic inverse of G. Note that conditional dependencies among X are not required to be preserved in the stochastic inverse as these are treated (simultaneously) as observed variables (highest topological order). Stuhlmüller et al. (2013); Paige & Wood (2016) presented a heuristic algorithm for constructing such stochastic inverses where the structure is a DAG (an example is given in Figure 3- [b]). However, these DAGs, though preserving all conditional dependencies, may omit many independencies and add new edges between layers.\n",
      "We avoid limiting G Inv to a DAG and instead limit it to be a projection of another latent structure (Pearl, 2009). That is, we assume the presence of additional hidden variables Q that are not in G Inv but induce dependency 2 among H. For clarity, we omit these variables from the graph and use bi-directional edges to represent the dependency induced by them. An example is given in Figure 3- [c] where a bi-directional edge represents the effect of some variable Q ∈ Q on H A and H B . We construct G Inv in two steps:\n",
      "1. Invert all G edges (invert inter-layer connectivity).\n",
      "2. Connect each pair of latent variables, sharing a common child in G, with a bi-directional edge.\n",
      "This simple procedure ensures G G Inv over X ∪ H while maintaining the exact same number of edges between the layers (Proposition 1, Appendix A). \n",
      "PAPER CONSTRUCTING A DISCRIMINATIVE GRAPH:\n",
      "Recall that G encodes the generative distribution of X and G Inv is the stochastic inverse. We further construct a discriminative graph G D by replacing bi-directional dependency relations in G Inv , induced by Q, with explaining-away relations by adding the observed class variable Y . Node Y is set in G D to be the common child of the leaves in G Inv (latents introduced after testing marginal independencies) (see an example in Figure 3- [d]). This preserves the conditional dependency relations of G Inv . That is, G D can mimic G Inv over X and H given Y (Proposition 2, Appendix A). It is interesting to note that the generative and discriminative graphs share the exact same inter-layer connectivity (inverted edge-directions). Moreover, introducing node Y provides an \"explaining away\" relation between latents, uniquely for the classification task at hand.\n",
      "PAPER CONSTRUCTING A FEED-FORWARD NEURAL NETWORK:\n",
      "We construct a neural network based on the connectivity in G D . Sigmoid belief networks (Neal, 1992) have been shown to be powerful neural network density estimators (Larochelle & Murray, 2011;Germain et al., 2015). In these networks, conditional probabilities are defined as logistic regressors. Similarly, for G D we may define for each latent variable H ∈ H,\n",
      "p(H = 1|X ) = sigm W X + b (3)\n",
      "where sigm(x) = 1/(1 + exp(−x)), X = P a(H ; G D ), and (W , b ) are the parameters of the neural network. Nair & Hinton (2010) proposed replacing each binary stochastic node H by an infinite number of copies having the same weights but with decreasing bias offsets by one. They showed that this infinite set can be approximated by\n",
      "N i=1 sigm(v − i + 0.5) ≈ log(1 + e v ),(4)\n",
      "where v = W X + b . They further approximate this function by max(0, v + ) where is a zerocentered Gaussian noise. Following these approximations, they provide an approximate probabilistic interpretation for the ReLU function, max(0, v). As demonstrated by Jarrett et al. (2009) and Nair & Hinton (2010), these units are able to learn better features for object classification in images.\n",
      "In order to further increase the representational power, we represent each H by a set of neurons having ReLU activation functions. That is, each latent variable H in G D is represented in the neural network by a dense (fully-connected) layer. Finally, the class node Y is represented by a softmax layer.\n",
      "PAPER RECURSIVE MULTI-LAYER STRUCTURE LEARNING:\n",
      "We now extend the method of learning the connectivity of a single layer into a method of learning multi-layered structures. The key idea is to recursively introduce a new and deeper latent layer by testing n-th order conditional independence (n is the condition set size) and connect it to latent layers created by previous recursive calls that tested conditional independence of order n + 1. The method is described in Algorithm 2. It is important to note that conditional independence is tested only between input variables X and condition sets do not include latent variables. Conditioning on latent variables or testing independence between them is not required as the algorithm adds these latent variables in a specific manner, preserving conditional dependencies between the input variables.\n",
      "Algorithm 2: Recursive Latent Structure Learning (multi-layer)\n",
      "RecurLatStruct (GX , X, Xex, n) Input: an initial DAG GX over observed X & exogenous nodes Xex and a desired resolution n.\n",
      "Output: G, a latent structure over X and H\n",
      "if the maximal indegree of GX (X) is below n + 1 then exit condition G ←−an observed layer X return G G X ←−IncreaseResolution(GX , n) n-th order independencies {XD, XA 1 , . . . , XA K } ←−SplitAutonomous(X, G X ) identify autonomies for i ∈ {1 . . . K} do GA i ←− RecurLatStruct(G X , XA i , Xex, n + 1) a recursive call GD ←− RecurLatStruct(G X , XD, Xex ∪ {XA i } K i=1 , n + 1) a recursive call G ←− Group(GD, GA 1 , . . . , GA K ) merge results create latent variables H (n) = {H (n) 1 , . . . , H (n) K } in G create a latent layer set each H (n) i\n",
      "to be a parent of {HA\n",
      "(n+1) i ∪ H (n+1) D } connectwhere\n",
      "HA (n+1) iand\n",
      "H (n+1) D\n",
      "are the sets of parentless latents in GA i and GD, respectively.\n",
      "PAPER return G:\n",
      "The algorithm maintains and recursively updates an auxiliary graph G X (a CPDAG) over X and utilizes it to construct G. Yehezkel & Lerner (2009) introduced an efficient algorithm (RAI) for constructing a CPDAG over X by a recursive application of conditional independence tests with increasing condition set sizes (n). Our algorithm is based on this framework for updating the auxiliary graph G X (Algorithm 2, lines 5 and 6).\n",
      "The algorithm starts with n = 0, G X a complete graph, and a set of exogenous nodes X ex = ∅. The set X ex is exogenous to G X and consists of parents of X.\n",
      "The function IncreaseResolution (Algorithm 2-line 5) disconnects (in G X ) conditionally independent variables in two steps. First, it tests dependency between X ex and X, i.e., X ⊥ ⊥ X |S for every connected pair X ∈ X and X ∈ X ex given a condition set S ⊂ {X ex ∪ X} of size n.\n",
      "Next, it tests dependency within X, i.e., X i ⊥ ⊥ X j |S for every connected pair X i , X j ∈ X given a condition set S ⊂ {X ex ∪ X} of size n. After removing the corresponding edges, the remaining edges are directed by applying two rules (Pearl, 2009;Spirtes et al., 2000). First, v-structures are identified and directed. Then, edges are continually directed, by avoiding the creation of new v-structures and directed cycles, until no more edges can be directed. Following the terminology of Yehezkel & Lerner (2009), we say that this function increases the graph d-separation resolution from n − 1 to n.\n",
      "The function SplitAutonomous (Algorithm 2-line 6) identifies autonomous sets in a graph in two steps, as described in Algorithm 1 lines 7 and 8. An autonomous set in G X includes all its nodes' parents (complying with the Markov property) and therefore a corresponding latent structure can be constructed independently using a recursive call. Thus, the algorithm is recursively and independently called for the ancestor sets (Algorithm 2 lines 7-8), and then called for the descendant set while treating the ancestor sets as exogenous (Algorithm 2 line 9).\n",
      "[a] Each recursive call returns a latent structure for each autonomous set. Recall that each latent structure encodes a generative distribution over the observed variables where layer H (n+1) , the last added layer (parentless nodes), is a representation of the input X ⊂ X. By considering only layer H (n+1) of each latent structure, we have the same simple scenario discussed in Section 2-learning the connectivity between H (n) , a new latent layer, and H (n+1) , treated as an \"input\" layer. Thus, latent variables are introduced as parents of the H (n+1) layers, as described in Algorithm 2 lines 11-13. A simplified example is given in Figure 4.\n",
      "C E D B A [b] C E D B A [c] C E D B A HC HD [d] C E D B A\n",
      "HA HB HC HD\n",
      "Next, a stochastic inverse G Inv is constructed as described in Section 2-all the edge directions are inverted and bi-directional edges are added between every pair of latents sharing a common child in G. An example graph G and a corresponding stochastic inverse G Inv are given in Figure 5. A discriminative structure G D is then constructed by removing all the bi-directional edges and adding the class node Y as a common child of layer H (0) , the last latent layer that is added (Figure 5-[c]). Finally, a neural network is constructed based on the connectivity of G D . That is, each latent node, H ∈ H (n) , is replaced by a set of neurons, and each edge between two latents, H ∈ H (n) and H ∈ H (n+1) , is replaced by a bipartite graph connecting the neurons corresponding to H and H .\n",
      "PAPER RELATED WORK:\n",
      "Recent studies have focused on automating the exploration of the design space, posing it as a hyperparameter optimization problem and proposing various approaches to solve it. (Miconi, 2016) learns the topology of an RNN network introducing structural parameters into the model and optimize them along with the model weights by the common gradient descent methods. Smith et al. ( 2016) takes a similar approach incorporating the structure learning into the parameter learning scheme, gradually growing the network up to a maximum size.\n",
      "A common approach is to define the design space in a way that enables a feasible exploration process and design an effective method for exploring it. Zoph & Le (2016) (NAS) first define a set of hyper-parameters characterizing a layer (number of filters, kernel size, stride). Then they use a controller-RNN for finding the optimal sequence of layer configurations for a \"trainee network\". This is done using policy gradients (REINFORCE) for optimizing the objective function that is based on the accuracy achieved by the \"trainee\" on a validation set. Although this work demonstrates capabilities to solve large-scale problems (Imagenet), it comes with huge computational cost. In a following work, Zoph et al. (2017) address the same problem but apply a hierarchical approach. They use NAS to design network modules on a small-scale dataset (CIFAR-10) and transfer this knowledge to a large-scale problem by learning the optimal topology composed of these modules. Baker et al. (2016) use reinforcement learning as well and apply Q-learning with epsilon-greedy exploration strategy and experience replay. Negrinho & Gordon (2017) propose a language that allows a human expert to compactly represent a complex search-space over architectures and hyperparameters as a tree and then use methods such as MCTS or SMBO to traverse this tree. Smithson et al. (2016) present a multi objective design space exploration, taking into account not only the classification accuracy but also the computational cost. In order to reduce the cost involved in evaluating the network's accuracy, they train a Response Surface Model that predicts the accuracy at much lower cost, reducing the number of candidates that go through actual validation accuracy evaluation. Another common approach for architecture search is based on evolutionary strategies to define and search the design space. (Real et al., 2017;Miikkulainen et al., 2017) use evolutionary algorithm to evolve an initial model or blueprint based on its validation performance.\n",
      "Common to all these recent studies is the fact that structure learning is done in a supervised manner, eventually learning a discriminative model. Moreoever, these approaches require huge compute resources, rendering the solution unfeasible for most applications given limited compute and time resources.\n",
      "PAPER EXPERIMENTS:\n",
      "We evaluate the quality of the learned structure in two experiments:\n",
      "• Classification accuracy as a function of network depth and size for a structure learned directly from MNIST pixels.\n",
      "• Classification accuracy as a function of network size on a range of benchmarks and compared to common topologies.\n",
      "All the experiments were repeated five times where average and standard deviation of the classification accuracy were recorded. In all of our experiments, we used a ReLU function for activation, ADAM (Kingma & Ba, 2015) for optimization, and applied batch normalization (Ioffe & Szegedy, 2015) followed by dropout (Srivastava et al., 2014) to all the dense layers. All optimization hyperparameters that were tuned for the vanilla topologies were also used, without additional tuning, for the learned structures. For the learned structures, all layers were allocated an equal number of neurons. Threshold for independence tests, and the number of neurons-per-layer were selected by using a validation set. Only test-set accuracy is reported.\n",
      "Our structure learning algorithm was implemented using the Bayesian network toolbox (Murphy, 2001) and Matlab. We used Torch7 (Collobert et al., 2011a) and Keras (Chollet, 2015) with the TensorFlow (Abadi et al., 2015) back-end for optimizing the parameters of both the vanilla and learned structures.\n",
      "PAPER NETWORK DEPTH, NUMBER OF PARAMETERS, AND ACCURACY:\n",
      "We analyze the accuracy of structures learned by our algorithm as a function of the number of layers and parameters. Although network depth is automatically determined by the algorithm, it is implicitly controlled by the threshold used to test conditional independence (partial-correlation test in our experiments). For example, a high threshold may cause detection of many independencies leading to early termination of the algorithm and a shallow network (a low threshold has the opposite effect). Thus, four different networks having 2, 3, 4, and 5 layers, using four different thresholds, are learned for MNIST. We also select three configurations of network sizes: a baseline (normalized to 1.00), and two configurations in which the number of parameters is 0.5, and 0.375 of the baseline network (equal number of neurons are allocated for each layer).\n",
      "Classification accuracies are summarized in Table 1. When the number of neurons-per-layers is large enough (100%) a 3-layer network achieves the highest classification accuracy of 99.07% (standard deviation is 0.01) where a 2-layer dense network has only a slight degradation in accuracy, 99.04%. For comparison, networks with 2 and 3 fully connected layers (structure is not learned) with similar number of parameters achieve 98.4% and 98.75%, respectively. This demonstrates the efficiency of our algorithm when learning a structure having a small number of layers. In addition, for a smaller neuron allocation (50%), deeper structures learned by our algorithm have higher accuracy than shallower ones. However, a decrease in the neurons-per-layer allocation has a greater impact on accuracy for deeper structures.  MNIST images as a function of network depth and number of parameters (normalized). For comparison, when a structure is not learned, networks with 2 and 3 dense layers, achieve 98.4% and 98.75% accuracy, respectively (having the same size as learned structures at configuration \"100%\").\n",
      "PAPER LEARNING THE STRUCTURE OF THE DEEPEST LAYERS IN COMMON TOPOLOGIES:\n",
      "We evaluate the quality of learned structures using five image classification benchmarks. We compare the learned structures to common topologies (and simpler hand-crafted structures), which we call \"vanilla topologies\", with respect to network size and classification accuracy. The benchmarks and vanilla topologies are described in  In the first row we indicate that in one experiment a structure for MNIST was learned from the pixels and feature extracting convolutional layers were not used.\n",
      "Convolutional layers are powerful feature extractors for images exploiting domain knowledge, such as spatial smoothness, translational invariance, and symmetry. We therefore evaluate our algorithm by using the first convolutional layers of the vanilla topologies as \"feature extractors\" (mostly below 50% of the vanilla network size) and learning a deep structure from their output. That is, the deepest layers of the vanilla network (mostly over 50% of the network size) is removed and replaced by a structure learned by our algorithm in an unsupervised manner. Finally, a softmax layer is added and the entire network parameters are optimized.\n",
      "First, we demonstrate the effect of replacing a different amount of the deepest layers and the ability of the learned structure to replace feature extraction layers.  VGG-16 is the \"vanilla\" topology. For both, CIFAR 10/100 benchmarks, the learned structure achieves the highest accuracy by replacing all the layers that are deeper than layer conv.10. Moreover, accuracy is maintained when replacing the layers deeper than layer conv.7.\n",
      "One interesting phenomenon to note is that the highest accuracy is achieved at conv. 10 rather than at the \"classifier\" (the last dense layer). This might imply that although convolutional layers are useful at extracting features directly from images, they might be redundant for deeper layers. By using our structure learning algorithm to learn the deeper layers, accuracy of the overall structure increases with the benefit of having a compact network. An accuracy, similar to that of \"vanilla\" VGG-16, is achieved with a structure having 85% less total parameters (conv. 7) than the vanilla network, where the learned structure is over 50X smaller than the replaced part.\n",
      "Next, we evaluate the accuracy of the learned structure as a function of the number of parameters and compare it to a densely connected network (fully connected layers) having the same depth and size. For SVHN, we used the Batch Normalized Maxout Network in Network topology (Chang & Chen, 2015) and removed the deepest layers starting from the output of the second NiN block (MMLP-2-2). For CIFAR-10, we used the VGG-16 and removed the deepest layers starting from the output of conv.10 layer. For MNIST, a structure was learned directly from pixels. Results are depicted in Figure 6. It is evident that accuracy of the learned structures is significantly higher (error bars represent 2 standard deviations) than a set of fully connected layers, especially in cases where the network is limited to a small number of parameters.\n",
      "[a]  Finally, in Table 4 we provide a summary of network sizes and classification accuracies, achieved by replacing the deepest layers of common topologies (vanilla) with a learned structure. In the first row, a structure is learned directly from images; therefore, it does not have a \"vanilla\" topology as reference (a network with 3 fully-connected layers having similar size achieves 98.75% accuracy). In all the cases, the size of the learned structure is significantly smaller than the vanilla topology, and generally has an increase in accuracy.\n",
      "Comparison to other methods. Our structure learning algorithm runs efficiently on a standard desktop CPU, while providing structures with competitive classification accuracies and network sizes. For example, the lowest classification error rate achieved by our unsupervised algorithm for CIFAR 10 is 4.58% with a network of size 6M (WRN-40-4 row in Table 4). For comparison, the NAS algorithm (Zoph & Le, 2016) achieves error rates of 5.5% and 4.47% for networks of sizes 4.2M and 7.1M, respectively, and requires optimizing thousands of networks using hundreds of GPUs. For AlexNet network, recent methods for reducing the size of a pre-trained network (pruning while maintaining classification accuracy) achieve 5× (Denton et al., 2014) and 9× (Han et al., 2015;2016)   The number of parameters are reported for \"feature extraction\" (first layers of the vanilla topology), removed section (the deepest layers of the vanilla topology), and the learned structure that replaced the removed part. The sum of parameters in the \"feature extraction\" and removed parts equals to the vanilla topology size. The first row corresponds to learning a structure directly from image pixels.\n",
      "PAPER CONCLUSIONS:\n",
      "We presented a principled approach for learning the structure of deep neural networks. Our proposed algorithm learns in an unsupervised manner and requires small computational cost. The resulting structures encode a hierarchy of independencies in the input distribution, where a node in one layer may connect another node in any deeper layer, and depth is determined automatically.\n",
      "We demonstrated that our algorithm learns small structures, and maintains high classification accuracies for common image classification benchmarks. It is also demonstrated that while convolution layers are very useful at exploiting domain knowledge, such as spatial smoothness, translational invariance, and symmetry, they are mostly outperformed by a learned structure for the deeper layers. Moreover, while the use of common topologies (meta-architectures), for a variety of classification tasks is computationally inefficient, we would expect our approach to learn smaller and more accurate networks for each classification task, uniquely.\n",
      "As only unlabeled data is required for learning the structure, we expect our approach to be practical for many domains, beyond image classification, such as knowledge discovery, and plan to explore the interpretability of the learned structures.\n",
      "PAPER APPENDIX A PRESERVATION OF CONDITIONAL DEPENDENCE:\n",
      "Conditional dependence relations encoded by the genrative structure G are preserved by the discriminative structure G D conditioned on the class Y . That is, G D conditioned on Y can mimic G; denoted by preference relation G G D |Y . While the parameters of a model can learn to mimic conditional independence relations that are not expressed by the graph structure, they are not able to learn conditional dependence relations (Pearl, 2009). Proposition 1. Graph G Inv preserves all conditional dependencies in G (i.e., G G Inv ).\n",
      "Proof. Graph G Inv can be constructed using the procedures described by Stuhlmüller et al. (2013) where nodes are added, one-by-one, to G Inv in a reverse topological order (lowest first) and connected (as a child) to existing nodes in G Inv that d-separate it, according to G, from the remainder of G Inv . Paige & Wood (2016) showed that this method ensures the preservation of conditional dependence G G Inv . We set an equal topological order to every pair of latents (H i , H j ) sharing a common child in G. Hence, jointly adding nodes H i and H j to G Inv , connected by a bi-directional edge, requires connecting them (as children) only to their children and the parents of their children (H i and H j themselves, by definition) in G. That is, without loss of generality, node H i is d-separated from the remainder of G Inv given its children in G and H j .\n",
      "It is interesting to note that the stochastic inverse G Inv , constructed without adding inter-layer connections, preserves all conditional dependencies in G.\n",
      "Proof. It is only required to prove that the dependency relations that are represented by bi-directional edges in G Inv are preserved in G D . The proof follows directly from the d-separation criterion (Pearl, 2009). A latent pair {H, H } ⊂ H (n+1) , connected by a bi-directional edge in G Inv , cannot be d-separated by any set containing Y , as Y is a descendant of a common child of H and H . In Algorithm 2-line 12, a latent in H (n) is connected, as a child, to latents H (n+1) , and Y to H (0) . We formulate G Inv as a projection of another latent model (Pearl, 2009) where bi-directional edges represent dependency relations induced by latent variables Q. We construct a discriminative model by considering the effect of Q as an explaining-away relation induced by a class node Y . Thus, conditioned on Y , the discriminative graph G D preserves all conditional (and marginal) dependencies in G Inv . Proposition 3. Graph G D , conditioned on Y , preserves all conditional dependencies in G (i.e., G G D ).\n",
      "PAPER Proof. It immediately follows from Propositions:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 拼接final_title、final_abstract、main\n",
    "\n",
    "def concat_paper(row):\n",
    "    paper_text = \"PAPER Title:\\n{}\\nPAPER Abstract:\\n{}\\n{}\".format(row[\"final_title\"], row[\"final_abstract\"], row[\"main\"])\n",
    "    paper_text = replace_1n(paper_text)\n",
    "    return paper_text\n",
    "\n",
    "df_merge_drop[\"paper\"] = df_merge_drop.apply(lambda x: concat_paper(x), axis=1)\n",
    "print(df_merge_drop[\"paper\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75f32b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.100     4169.0\n",
       "0.250     4946.0\n",
       "0.500     5943.0\n",
       "0.750     7345.0\n",
       "0.900    10141.0\n",
       "0.950    12372.0\n",
       "0.990    17302.0\n",
       "0.995    19136.0\n",
       "0.999    21957.0\n",
       "1.000    22339.0\n",
       "Name: paper_count, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计paper单词数\n",
    "df_merge_drop[\"paper_count\"] = df_merge_drop[\"paper\"].map(lambda x: len(x.split()) if pd.notnull(x) else 0)\n",
    "df_merge_drop[\"paper_count\"].quantile(q=[0.1, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99, 0.995, 0.999, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95621e0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.100      72.00\n",
       "0.250     205.00\n",
       "0.500     392.00\n",
       "0.750     579.00\n",
       "0.900     794.00\n",
       "0.950     958.00\n",
       "0.990    1375.20\n",
       "0.995    1573.60\n",
       "0.999    2090.12\n",
       "1.000    4150.00\n",
       "Name: review_count, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计review单词数\n",
    "df_merge_drop[\"review_count\"] = df_merge_drop[\"c_content_str\"].map(lambda x: len(x.split()) if pd.notnull(x) else 0)\n",
    "df_merge_drop[\"review_count\"].quantile(q=[0.1, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99, 0.995, 0.999, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2c40bc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10     4518.0\n",
       "0.25     5347.0\n",
       "0.50     6379.0\n",
       "0.75     7838.0\n",
       "0.90    10648.0\n",
       "0.95    12875.0\n",
       "0.99    17821.2\n",
       "1.00    23254.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计paper+review单词数\n",
    "(df_merge_drop[\"paper_count\"] + df_merge_drop[\"review_count\"]).quantile(q=[0.1, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758da354",
   "metadata": {},
   "source": [
    "## 四、分别保存paper与review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95fdaeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重命名\n",
    "df_merge_drop.rename(columns={\"c_content_str\": \"review\"}, inplace=True)\n",
    "# 仅保留有用字段\n",
    "df_merge_drop = df_merge_drop[[\"forum\",\"r_order\",\"paper\",\"review\",\"paper_count\",\"review_count\",\"final_title\",\"final_abstract\",\"main\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b2843f",
   "metadata": {},
   "source": [
    "### I. 保存paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "48bbbef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forum</th>\n",
       "      <th>paper</th>\n",
       "      <th>paper_word_count</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ryjw_eAaZ</td>\n",
       "      <td>PAPER Title:\\nUnsupervised Deep Structure Lear...</td>\n",
       "      <td>6025</td>\n",
       "      <td>Unsupervised Deep Structure Learning by Recurs...</td>\n",
       "      <td>We introduce an unsupervised structure learnin...</td>\n",
       "      <td>PAPER INTRODUCTION:\\nOver the last decade, dee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rye7IMbAZ</td>\n",
       "      <td>PAPER Title:\\n Explicit Induction Bias for Tra...</td>\n",
       "      <td>5630</td>\n",
       "      <td>Explicit Induction Bias for Transfer Learning...</td>\n",
       "      <td>In inductive transfer learning, fine-tuning pr...</td>\n",
       "      <td>PAPER INTRODUCTION:\\nIt is now well known that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ryZElGZ0Z</td>\n",
       "      <td>PAPER Title:\\nDiscovery of Predictive Represen...</td>\n",
       "      <td>7365</td>\n",
       "      <td>Discovery of Predictive Representations With a...</td>\n",
       "      <td>The ability of an agent to {\\em discover} its ...</td>\n",
       "      <td>PAPER INTRODUCTION:\\nThe idea that an agent's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ryZ3KCy0W</td>\n",
       "      <td>PAPER Title:\\nLink Weight Prediction with Node...</td>\n",
       "      <td>3432</td>\n",
       "      <td>Link Weight Prediction with Node Embeddings</td>\n",
       "      <td>Application of deep learning has been successf...</td>\n",
       "      <td>PAPER INTRODUCTION:\\nDeep learning has outperf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ryUlhzWCZ</td>\n",
       "      <td>PAPER Title:\\nTRUNCATED HORIZON POLICY SEARCH:...</td>\n",
       "      <td>7205</td>\n",
       "      <td>TRUNCATED HORIZON POLICY SEARCH: COMBINING REI...</td>\n",
       "      <td>In this paper, we propose to combine imitation...</td>\n",
       "      <td>PAPER INTRODUCTION:\\nReinforcement Learning (R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18439</th>\n",
       "      <td>el1iPvMqqTY</td>\n",
       "      <td>PAPER Title:\\nSample-Efficient Mapspace Optimi...</td>\n",
       "      <td>3471</td>\n",
       "      <td>Sample-Efficient Mapspace Optimization for DNN...</td>\n",
       "      <td>Achieving high performance for machine learnin...</td>\n",
       "      <td>PAPER I. INTRODUCTION:\\nDomain-specific hardwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18443</th>\n",
       "      <td>DZvNrRNas6z</td>\n",
       "      <td>PAPER Title:\\nAsynchronous Decentralized Feder...</td>\n",
       "      <td>3123</td>\n",
       "      <td>Asynchronous Decentralized Federated Lifelong ...</td>\n",
       "      <td>Federated learning is a recent development in ...</td>\n",
       "      <td>PAPER INTRODUCTION:\\nMedical imaging, MRI (Mag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18444</th>\n",
       "      <td>u9zVZTg_Ky</td>\n",
       "      <td>PAPER Title:\\nPhysics-informed neural networks...</td>\n",
       "      <td>4857</td>\n",
       "      <td>Physics-informed neural networks integrating c...</td>\n",
       "      <td>Modelling and predicting the behaviour of infe...</td>\n",
       "      <td>PAPER INTRODUCTION:\\nThe emergence of severe a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18448</th>\n",
       "      <td>qkDCSV-RMt</td>\n",
       "      <td>PAPER Title:\\nSpectral Clustering Identifies H...</td>\n",
       "      <td>4408</td>\n",
       "      <td>Spectral Clustering Identifies High-risk Opioi...</td>\n",
       "      <td>National opioid prescribing guidelines and rel...</td>\n",
       "      <td>PAPER INTRODUCTION:\\nNational prescribing guid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>N0qlvDjnEv</td>\n",
       "      <td>PAPER Title:\\nRisk-Based Ring Vaccination: A S...</td>\n",
       "      <td>2907</td>\n",
       "      <td>Risk-Based Ring Vaccination: A Strategy for Pa...</td>\n",
       "      <td>Throughout an infectious disease crisis, resou...</td>\n",
       "      <td>PAPER Introduction:\\nDesigning control policie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3837 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             forum                                              paper  \\\n",
       "0        ryjw_eAaZ  PAPER Title:\\nUnsupervised Deep Structure Lear...   \n",
       "4        rye7IMbAZ  PAPER Title:\\n Explicit Induction Bias for Tra...   \n",
       "8        ryZElGZ0Z  PAPER Title:\\nDiscovery of Predictive Represen...   \n",
       "12       ryZ3KCy0W  PAPER Title:\\nLink Weight Prediction with Node...   \n",
       "16       ryUlhzWCZ  PAPER Title:\\nTRUNCATED HORIZON POLICY SEARCH:...   \n",
       "...            ...                                                ...   \n",
       "18439  el1iPvMqqTY  PAPER Title:\\nSample-Efficient Mapspace Optimi...   \n",
       "18443  DZvNrRNas6z  PAPER Title:\\nAsynchronous Decentralized Feder...   \n",
       "18444   u9zVZTg_Ky  PAPER Title:\\nPhysics-informed neural networks...   \n",
       "18448   qkDCSV-RMt  PAPER Title:\\nSpectral Clustering Identifies H...   \n",
       "18452   N0qlvDjnEv  PAPER Title:\\nRisk-Based Ring Vaccination: A S...   \n",
       "\n",
       "       paper_word_count                                              title  \\\n",
       "0                  6025  Unsupervised Deep Structure Learning by Recurs...   \n",
       "4                  5630   Explicit Induction Bias for Transfer Learning...   \n",
       "8                  7365  Discovery of Predictive Representations With a...   \n",
       "12                 3432        Link Weight Prediction with Node Embeddings   \n",
       "16                 7205  TRUNCATED HORIZON POLICY SEARCH: COMBINING REI...   \n",
       "...                 ...                                                ...   \n",
       "18439              3471  Sample-Efficient Mapspace Optimization for DNN...   \n",
       "18443              3123  Asynchronous Decentralized Federated Lifelong ...   \n",
       "18444              4857  Physics-informed neural networks integrating c...   \n",
       "18448              4408  Spectral Clustering Identifies High-risk Opioi...   \n",
       "18452              2907  Risk-Based Ring Vaccination: A Strategy for Pa...   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      We introduce an unsupervised structure learnin...   \n",
       "4      In inductive transfer learning, fine-tuning pr...   \n",
       "8      The ability of an agent to {\\em discover} its ...   \n",
       "12     Application of deep learning has been successf...   \n",
       "16     In this paper, we propose to combine imitation...   \n",
       "...                                                  ...   \n",
       "18439  Achieving high performance for machine learnin...   \n",
       "18443  Federated learning is a recent development in ...   \n",
       "18444  Modelling and predicting the behaviour of infe...   \n",
       "18448  National opioid prescribing guidelines and rel...   \n",
       "18452  Throughout an infectious disease crisis, resou...   \n",
       "\n",
       "                                                    main  \n",
       "0      PAPER INTRODUCTION:\\nOver the last decade, dee...  \n",
       "4      PAPER INTRODUCTION:\\nIt is now well known that...  \n",
       "8      PAPER INTRODUCTION:\\nThe idea that an agent's ...  \n",
       "12     PAPER INTRODUCTION:\\nDeep learning has outperf...  \n",
       "16     PAPER INTRODUCTION:\\nReinforcement Learning (R...  \n",
       "...                                                  ...  \n",
       "18439  PAPER I. INTRODUCTION:\\nDomain-specific hardwa...  \n",
       "18443  PAPER INTRODUCTION:\\nMedical imaging, MRI (Mag...  \n",
       "18444  PAPER INTRODUCTION:\\nThe emergence of severe a...  \n",
       "18448  PAPER INTRODUCTION:\\nNational prescribing guid...  \n",
       "18452  PAPER Introduction:\\nDesigning control policie...  \n",
       "\n",
       "[3837 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取出paper\n",
    "df_paper_final = df_merge_drop[[\"forum\", \"paper\", \"paper_count\",\"final_title\", \"final_abstract\", \"main\"]].drop_duplicates(keep=\"first\")\n",
    "# 重命名\n",
    "df_paper_final.rename(columns={\"paper_count\": \"paper_word_count\", \"final_title\": \"title\", \"final_abstract\": \"abstract\"}, inplace=True)\n",
    "df_paper_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "119114b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3837, 6)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paper_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c34776df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存paper\n",
    "df_paper_final.to_csv(\"./processed_paper_final.csv\", index=False)\n",
    "del df_paper_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c63d330",
   "metadata": {},
   "source": [
    "### II. 保存review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fcf0c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出review\n",
    "df_review_final = df_merge_drop[[\"forum\", \"r_order\", \"review\", \"review_count\"]]\n",
    "# 重命名\n",
    "df_review_final.rename(columns={\"review_count\": \"review_word_count\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ae767101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3837 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3837/3837 [00:00<00:00, 4412.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# 将r_order替换成由1开始的基本顺序计数\n",
    "r_orders = []\n",
    "df_review_final_order = pd.DataFrame()\n",
    "\n",
    "for idx, fm in tqdm(df_review_final.groupby(\"forum\")):\n",
    "    for order, rv in enumerate(fm.sort_values(by=\"r_order\", ascending=True)[\"r_order\"]):\n",
    "        r_orders.append(order + 1)\n",
    "    df_review_final_order = pd.concat([df_review_final_order, fm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf5f45fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forum</th>\n",
       "      <th>r_order</th>\n",
       "      <th>review</th>\n",
       "      <th>review_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18049</th>\n",
       "      <td>-0sywUv8ryL</td>\n",
       "      <td>1</td>\n",
       "      <td>REVIEW title:\\nInteresting problem but needs a...</td>\n",
       "      <td>1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18050</th>\n",
       "      <td>-0sywUv8ryL</td>\n",
       "      <td>2</td>\n",
       "      <td>REVIEW title:\\nReview for \"SoK: Virtualization...</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18051</th>\n",
       "      <td>-0sywUv8ryL</td>\n",
       "      <td>3</td>\n",
       "      <td>REVIEW title:\\nLack of technical depth and org...</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18052</th>\n",
       "      <td>-0sywUv8ryL</td>\n",
       "      <td>4</td>\n",
       "      <td>REVIEW title:\\nReview: Virtualization Classifi...</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18053</th>\n",
       "      <td>-0sywUv8ryL</td>\n",
       "      <td>5</td>\n",
       "      <td>REVIEW metareview:\\n**Meta-review Security are...</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             forum  r_order  \\\n",
       "18049  -0sywUv8ryL        1   \n",
       "18050  -0sywUv8ryL        2   \n",
       "18051  -0sywUv8ryL        3   \n",
       "18052  -0sywUv8ryL        4   \n",
       "18053  -0sywUv8ryL        5   \n",
       "\n",
       "                                                  review  review_word_count  \n",
       "18049  REVIEW title:\\nInteresting problem but needs a...               1475  \n",
       "18050  REVIEW title:\\nReview for \"SoK: Virtualization...                584  \n",
       "18051  REVIEW title:\\nLack of technical depth and org...                271  \n",
       "18052  REVIEW title:\\nReview: Virtualization Classifi...                456  \n",
       "18053  REVIEW metareview:\\n**Meta-review Security are...                188  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_final_order[\"r_order\"] = r_orders\n",
    "df_review_final_order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "53bd46fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17881, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_final_order.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d54ea2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存review\n",
    "df_review_final_order.to_csv(\"./processed_review_final.csv\", index=False)\n",
    "del df_review_final_order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d06cda",
   "metadata": {},
   "source": [
    "## 五、组织数据格式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680de18",
   "metadata": {},
   "source": [
    "### I. 单轮形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73212115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Please reivew this paper or give some sugguestion.\n",
      "\n",
      "Assistant: Ok, please provide detailed infomation or provide paper to review.\n",
      "\n",
      "User: This is the paper:\n",
      "{paper}\n",
      "\n",
      "Assistant: This is the review:\n",
      "{reivew}\n"
     ]
    }
   ],
   "source": [
    "# 单轮组织格式展示\n",
    "template_single_show = \"User: Please reivew this paper or give some sugguestion.\\n\\nAssistant: Ok, please provide detailed infomation or provide paper to review.\\n\\nUser: This is the paper:\\n{paper}\\n\\nAssistant: This is the review:\\n{reivew}\"\n",
    "print(template_single_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3161bbeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Please reivew this paper or give some sugguestion.\n",
      "\n",
      "Assistant: Ok, please provide detailed infomation or provide paper to review.\n",
      "\n",
      "User: This is the paper:\n",
      "PAPER Title:\n",
      "Unsupervised Deep Structure Learning by Recursive Dependency Analysis\n",
      "PAPER Abstract:\n",
      "We introduce an unsupervised structure learning algorithm for deep, feed-forward, neural networks. We propose a new interpretation for depth and inter-layer connectivity where a hierarchy of independencies in the input distribution is encoded in the network structure. This results in structures allowing neurons to connect to neurons in any deeper layer skipping intermediate layers. Moreover, neurons in deeper layers encode low-order (small condition sets) independencies and have a wide scope of the input, whereas neurons in the first layers encode higher-order (larger condition sets) independencies and have a narrower scope. Thus, the depth of the network is automatically determined---equal to the maximal order of independence in the input distribution, which is the recursion-depth of the algorithm. The proposed algorithm constructs two main graphical models: 1) a generative latent graph (a deep belief network) learned from data and 2) a deep discriminative graph constructed from the generative latent graph. We prove that conditional dependencies between the nodes in the learned generative latent graph are preserved in the class-conditional discriminative graph. Finally, a deep neural network structure is constructed based on the discriminative graph. We demonstrate on image classification benchmarks that the algorithm replaces the deepest layers (convolutional and dense layers) of common convolutional networks, achieving high classification accuracy, while constructing significantly smaller structures. The proposed structure learning algorithm requires a small computational cost and runs efficiently on a standard desktop CPU.\n",
      "PAPER INTRODUCTION:\n",
      "Over the last decade, deep neural networks have proven their effectiveness in solving many challenging problems in various domains such as speech recognition (Graves & Schmidhuber, 2005), computer vision (Krizhevsky et al., 2012;Girshick et al., 2014;Simonyan & Zisserman, 2014; and machine translation (Collobert et al., 2011b). As compute resources became more available, large scale models having millions of parameters could be trained on massive volumes of data, to achieve state-of-the-art solutions for these high dimensionality problems. Building these models requires various design choices such as network topology, cost function, optimization technique, and the configuration of related hyper-parameters.\n",
      "In this paper, we focus on the design of network topology-structure learning. Generally, exploration of this design space is a time consuming iterative process that requires close supervision by a human expert. Many studies provide guidelines for design choices such as network depth (Simonyan & Zisserman, 2014), layer width (Zagoruyko & Komodakis, 2016), building blocks , and connectivity (He et al., 2016;Huang et al., 2016). Based on these guidelines, these studies propose several meta-architectures, trained on huge volumes of data. These were applied to other tasks by leveraging the representational power of their convolutional layers and fine-tuning their deepest layers for the task at hand Hinton et al., 2015;Long et al., 2015;. However, these meta-architecture may be unnecessarily large and require large computational power and memory for training and inference.\n",
      "The problem of model structure learning has been widely researched for many years in the probabilistic graphical models domain. Specifically, Bayesian networks for density estimation and causal discovery (Pearl, 2009;Spirtes et al., 2000). Two main approaches were studied: score-based (search-and-score) and constraint-based. Score-based approaches combine a scoring function, such as BDe (Cooper & Herskovits, 1992) and BIC (Ripley, 2007), with a strategy for searching through the space of structures, such as greedy equivalence search (Chickering, 2002). Adams et al. (2010) introduced an algorithm for sampling deep belief networks (generative model) and demonstrated its applicability to high-dimensional image datasets.\n",
      "Constraint-based approaches (Pearl, 2009;Spirtes et al., 2000) find the optimal structures in the large sample limit by testing conditional independence (CI) between pairs of variables. They are generally faster than score-based approaches (Yehezkel & Lerner, 2009) and have a well-defined stopping criterion (e.g., maximal order of conditional independence). However, these methods are sensitive to errors in the independence tests, especially in the case of high-order conditional-independence tests and small training sets.\n",
      "Motivated by these methods, we propose a new interpretation for depth and inter-layer connectivity in deep neural networks. We derive a structure learning algorithm such that a hierarchy of independencies in the input distribution is encoded in the network structure, where the first layers encode higher-order independencies than deeper layers. Thus, the number of layers is automatically determined. Moreover, a neuron in a layer is allowed to connect to neurons in deeper layers skipping intermediate layers. An example of a learned structure, for MNIST, is given in Figure 1.\n",
      "We describe our recursive algorithm in two steps. In Section 2 we describe a base case-a singlelayer structure learning. In Section 3 we describe multi-layer structure learning by applying the key concepts of the base case, recursively (proofs are provided in Appendix A). In Section 4 we discuss related work. We provide experimental results in Section 5, and conclude in Section 6.\n",
      "Preliminaries. Consider X = {X i } N i=1 a set of observed (input) random variables, H = {H j } K j=1\n",
      "a set of latent variables, and Y a class variable. Our algorithm constructs three graphical models and an auxiliary graph. Each variable is represented by a single node and a single edge may connect two distinct nodes. Graph G is a generative DAG defined over the observed and latent variables X ∪ H. Graph G Inv is called a stochastic inverse of G. Graph G D is a discriminative model defined over the observed, latent, and class variables X ∪ H ∪ Y . An auxiliary graph G X is defined over X (a CPDAG; an equivalence class of a Bayesian network) and is generated and maintained as an internal state of the algorithm. The parents set of a node X in G is denoted P a(X; G). The order of an independence relation is defined to be the condition set size. For example, if X 1 and X 2 are independent given X 3 and X 4 , denoted X 1 ⊥ ⊥ X 2 |{X 3 , X 4 }, then the independence order is two.\n",
      "output layer gather layer dense layer input layer conc atenate copy Figure 1: An example of a structure learned by our algorithm (classifying MNIST digits). Neurons in a layer may connect to neurons in any deeper layer. Depth is determined automatically. Each gather layer selects a subset of the input, where each input variable is gathered only once. A neural route, starting with a gather layer, passes through densely connected layers where it may split (copy) and merge (concatenate) with other routes in correspondence with the hierarchy of independencies identified by the algorithm. All routes merge into the final output layer (e.g., a softmax layer).\n",
      "PAPER SINGLE LAYER STRUCTURE LEARNING:\n",
      "We start by describing the key concepts of our approach using a simple scenario: learning the connectivity of a single-layer neural network.\n",
      "PAPER CONSTRUCTING A GENERATIVE GRAPH:\n",
      "Assume the input joint distribution p(X) complies with the following property.\n",
      "Assumption 1. The joint distribution p(X) is faithful to a DAG G over observed X and latent nodes H, where for all X ∈ X and H ∈ H, P a(X; G) ⊆ H and P a(H; G) ⊆ H\\H.\n",
      "p X; G = p X, H; G dH = p H N i=1 p X i P a(X i ; G) dH.\n",
      "(1)\n",
      "Note that the generative graphical model G can be described as a layered deep belief network where parents of a node in layer m can be in any deeper layer, indexes greater than m, and not restricted to the next layer m + 1. This differs from the common definition of deep belief networks (Hinton et al., 2006;Adams et al., 2010) where the parents are restricted to layer m + 1.\n",
      "It is desired to learn an efficient graph G having small sets of parents and a simple factorization of p(H) while maintaining high expressive power. We first construct an auxiliary graph, a CPDAG (Spirtes et al., 2000), G X over X (an equivalence class of a fully visible Bayesian network) encoding only marginal independencies 1 (empty condition sets) and then construct G such that it can mimic G X over X, denoted G X G (Pearl, 2009). That is, preserving all conditional dependencies of X in G X .\n",
      "The simplest connected DAG that encodes statistical independence is the v-structure, a structure with three nodes X 1 → X 3 ← X 2 in which X 1 and X 2 are marginally independent X 1 ⊥ ⊥ X 2 and conditionally dependent X 1 ⊥ ⊥X 2 |X 3 . In graphs encoding only marginal independencies, dependent nodes form a clique. We follow the procedure described by Yehezkel & Lerner (2009) and decompose X into autonomous sets (complying with the Markov property) where one set, denoted X D (descendants), is the common child of all other sets, denoted X A1 , . . . , X AK (ancestor sets). We select X D to be the set of nodes that have the lowest topological order in G X . Then, by removing X D from G X (temporarily for this step), the resulting K disjoint sets of nodes (corresponding to K disjoint substructures) form the K ancestor sets {X Ai } K i=1 . See an example in Figure 2. Next, G is initialized to an empty graph over X. Then, for each ancestor set X Ai a latent variable H i is introduced and assigned to be a common parent of the pair (X Ai , X D ). Thus,\n",
      "p X; G = K i=1   p H i X∈XA i p X H i   X ∈XD p X H dH.\n",
      "(2)\n",
      "Note that the parents of two ancestor sets are distinct, whereas the parents set of the descendant set is composed of all the latent variables.\n",
      "In the auxiliary graph G X , for each of the resulting v-structures (X Ai → X D ← X Aj ), a link between a parent and a child can be replaced by a common latent parent without introducing new independencies. For example, in Figure 2-[b], X A1 = {A}, X A2 = {B}, and X D = {C, D, E}.\n",
      "Adding a common latent parent (Figure 3-[a]) H A (or H B ) and removing all the edges from X A1 (or X A2 ) to X D preserves the conditional dependence A ⊥ ⊥ B|{C, D, E}.\n",
      "Algorithm 1 summarizes the procedure of constructing G having a single latent layer. Note that we do not claim to identify the presence of confounders and their inter-relations as in Elidan et al. (2001); Silva et al. (2006); Asbeh & Lerner (2016). Instead, we augment a fully observed Bayesian network with latent variables, while preserving conditional dependence.\n",
      "[a] \n",
      "C E D B A [b] C E D B A\n",
      ", X A1 = {A}, X A2 = {B}-disjoint if {C, D, E} is removed from the graph. [a] C E D B A HA HB [b] C E D B A HA HB [c] C E D B A HA HB [d] C E D B A HA HB Y Figure 3: [a] An example of a graph G (corresponding to G X in Figure 2-[b]). [b]\n",
      "A stochastic inverse generated by the algorithm presented by Stuhlmüller et al. (2013).\n",
      "[c] A stochastic inverse generated by our method where the graph is a projection of a latent structure. A dependency induced by a latent Q is described using a bi-directional edge\n",
      "H A ↔ H B . [d] A discriminative structure G D\n",
      "having a class node Y that provides an explaining away relation for\n",
      "H A ↔ H B .\n",
      "That is, the latent Q is replaced by an observed common child Y .\n",
      "PAPER CONSTRUCTING A STOCHASTIC INVERSE:\n",
      "It is important to note that G represents a generative distribution of X and is constructed in an unsupervised manner (class variable Y is ignored). Hence, we construct G Inv , a graphical model that preserves all conditional dependencies in G but has a different node ordering in which the observed variables, X, have the highest topological order (parentless)-a stochastic inverse of G. Note that conditional dependencies among X are not required to be preserved in the stochastic inverse as these are treated (simultaneously) as observed variables (highest topological order). Stuhlmüller et al. (2013); Paige & Wood (2016) presented a heuristic algorithm for constructing such stochastic inverses where the structure is a DAG (an example is given in Figure 3- [b]). However, these DAGs, though preserving all conditional dependencies, may omit many independencies and add new edges between layers.\n",
      "We avoid limiting G Inv to a DAG and instead limit it to be a projection of another latent structure (Pearl, 2009). That is, we assume the presence of additional hidden variables Q that are not in G Inv but induce dependency 2 among H. For clarity, we omit these variables from the graph and use bi-directional edges to represent the dependency induced by them. An example is given in Figure 3- [c] where a bi-directional edge represents the effect of some variable Q ∈ Q on H A and H B . We construct G Inv in two steps:\n",
      "1. Invert all G edges (invert inter-layer connectivity).\n",
      "2. Connect each pair of latent variables, sharing a common child in G, with a bi-directional edge.\n",
      "This simple procedure ensures G G Inv over X ∪ H while maintaining the exact same number of edges between the layers (Proposition 1, Appendix A). \n",
      "PAPER CONSTRUCTING A DISCRIMINATIVE GRAPH:\n",
      "Recall that G encodes the generative distribution of X and G Inv is the stochastic inverse. We further construct a discriminative graph G D by replacing bi-directional dependency relations in G Inv , induced by Q, with explaining-away relations by adding the observed class variable Y . Node Y is set in G D to be the common child of the leaves in G Inv (latents introduced after testing marginal independencies) (see an example in Figure 3- [d]). This preserves the conditional dependency relations of G Inv . That is, G D can mimic G Inv over X and H given Y (Proposition 2, Appendix A). It is interesting to note that the generative and discriminative graphs share the exact same inter-layer connectivity (inverted edge-directions). Moreover, introducing node Y provides an \"explaining away\" relation between latents, uniquely for the classification task at hand.\n",
      "PAPER CONSTRUCTING A FEED-FORWARD NEURAL NETWORK:\n",
      "We construct a neural network based on the connectivity in G D . Sigmoid belief networks (Neal, 1992) have been shown to be powerful neural network density estimators (Larochelle & Murray, 2011;Germain et al., 2015). In these networks, conditional probabilities are defined as logistic regressors. Similarly, for G D we may define for each latent variable H ∈ H,\n",
      "p(H = 1|X ) = sigm W X + b (3)\n",
      "where sigm(x) = 1/(1 + exp(−x)), X = P a(H ; G D ), and (W , b ) are the parameters of the neural network. Nair & Hinton (2010) proposed replacing each binary stochastic node H by an infinite number of copies having the same weights but with decreasing bias offsets by one. They showed that this infinite set can be approximated by\n",
      "N i=1 sigm(v − i + 0.5) ≈ log(1 + e v ),(4)\n",
      "where v = W X + b . They further approximate this function by max(0, v + ) where is a zerocentered Gaussian noise. Following these approximations, they provide an approximate probabilistic interpretation for the ReLU function, max(0, v). As demonstrated by Jarrett et al. (2009) and Nair & Hinton (2010), these units are able to learn better features for object classification in images.\n",
      "In order to further increase the representational power, we represent each H by a set of neurons having ReLU activation functions. That is, each latent variable H in G D is represented in the neural network by a dense (fully-connected) layer. Finally, the class node Y is represented by a softmax layer.\n",
      "PAPER RECURSIVE MULTI-LAYER STRUCTURE LEARNING:\n",
      "We now extend the method of learning the connectivity of a single layer into a method of learning multi-layered structures. The key idea is to recursively introduce a new and deeper latent layer by testing n-th order conditional independence (n is the condition set size) and connect it to latent layers created by previous recursive calls that tested conditional independence of order n + 1. The method is described in Algorithm 2. It is important to note that conditional independence is tested only between input variables X and condition sets do not include latent variables. Conditioning on latent variables or testing independence between them is not required as the algorithm adds these latent variables in a specific manner, preserving conditional dependencies between the input variables.\n",
      "Algorithm 2: Recursive Latent Structure Learning (multi-layer)\n",
      "RecurLatStruct (GX , X, Xex, n) Input: an initial DAG GX over observed X & exogenous nodes Xex and a desired resolution n.\n",
      "Output: G, a latent structure over X and H\n",
      "if the maximal indegree of GX (X) is below n + 1 then exit condition G ←−an observed layer X return G G X ←−IncreaseResolution(GX , n) n-th order independencies {XD, XA 1 , . . . , XA K } ←−SplitAutonomous(X, G X ) identify autonomies for i ∈ {1 . . . K} do GA i ←− RecurLatStruct(G X , XA i , Xex, n + 1) a recursive call GD ←− RecurLatStruct(G X , XD, Xex ∪ {XA i } K i=1 , n + 1) a recursive call G ←− Group(GD, GA 1 , . . . , GA K ) merge results create latent variables H (n) = {H (n) 1 , . . . , H (n) K } in G create a latent layer set each H (n) i\n",
      "to be a parent of {HA\n",
      "(n+1) i ∪ H (n+1) D } connectwhere\n",
      "HA (n+1) iand\n",
      "H (n+1) D\n",
      "are the sets of parentless latents in GA i and GD, respectively.\n",
      "PAPER return G:\n",
      "The algorithm maintains and recursively updates an auxiliary graph G X (a CPDAG) over X and utilizes it to construct G. Yehezkel & Lerner (2009) introduced an efficient algorithm (RAI) for constructing a CPDAG over X by a recursive application of conditional independence tests with increasing condition set sizes (n). Our algorithm is based on this framework for updating the auxiliary graph G X (Algorithm 2, lines 5 and 6).\n",
      "The algorithm starts with n = 0, G X a complete graph, and a set of exogenous nodes X ex = ∅. The set X ex is exogenous to G X and consists of parents of X.\n",
      "The function IncreaseResolution (Algorithm 2-line 5) disconnects (in G X ) conditionally independent variables in two steps. First, it tests dependency between X ex and X, i.e., X ⊥ ⊥ X |S for every connected pair X ∈ X and X ∈ X ex given a condition set S ⊂ {X ex ∪ X} of size n.\n",
      "Next, it tests dependency within X, i.e., X i ⊥ ⊥ X j |S for every connected pair X i , X j ∈ X given a condition set S ⊂ {X ex ∪ X} of size n. After removing the corresponding edges, the remaining edges are directed by applying two rules (Pearl, 2009;Spirtes et al., 2000). First, v-structures are identified and directed. Then, edges are continually directed, by avoiding the creation of new v-structures and directed cycles, until no more edges can be directed. Following the terminology of Yehezkel & Lerner (2009), we say that this function increases the graph d-separation resolution from n − 1 to n.\n",
      "The function SplitAutonomous (Algorithm 2-line 6) identifies autonomous sets in a graph in two steps, as described in Algorithm 1 lines 7 and 8. An autonomous set in G X includes all its nodes' parents (complying with the Markov property) and therefore a corresponding latent structure can be constructed independently using a recursive call. Thus, the algorithm is recursively and independently called for the ancestor sets (Algorithm 2 lines 7-8), and then called for the descendant set while treating the ancestor sets as exogenous (Algorithm 2 line 9).\n",
      "[a] Each recursive call returns a latent structure for each autonomous set. Recall that each latent structure encodes a generative distribution over the observed variables where layer H (n+1) , the last added layer (parentless nodes), is a representation of the input X ⊂ X. By considering only layer H (n+1) of each latent structure, we have the same simple scenario discussed in Section 2-learning the connectivity between H (n) , a new latent layer, and H (n+1) , treated as an \"input\" layer. Thus, latent variables are introduced as parents of the H (n+1) layers, as described in Algorithm 2 lines 11-13. A simplified example is given in Figure 4.\n",
      "C E D B A [b] C E D B A [c] C E D B A HC HD [d] C E D B A\n",
      "HA HB HC HD\n",
      "Next, a stochastic inverse G Inv is constructed as described in Section 2-all the edge directions are inverted and bi-directional edges are added between every pair of latents sharing a common child in G. An example graph G and a corresponding stochastic inverse G Inv are given in Figure 5. A discriminative structure G D is then constructed by removing all the bi-directional edges and adding the class node Y as a common child of layer H (0) , the last latent layer that is added (Figure 5-[c]). Finally, a neural network is constructed based on the connectivity of G D . That is, each latent node, H ∈ H (n) , is replaced by a set of neurons, and each edge between two latents, H ∈ H (n) and H ∈ H (n+1) , is replaced by a bipartite graph connecting the neurons corresponding to H and H .\n",
      "PAPER RELATED WORK:\n",
      "Recent studies have focused on automating the exploration of the design space, posing it as a hyperparameter optimization problem and proposing various approaches to solve it. (Miconi, 2016) learns the topology of an RNN network introducing structural parameters into the model and optimize them along with the model weights by the common gradient descent methods. Smith et al. ( 2016) takes a similar approach incorporating the structure learning into the parameter learning scheme, gradually growing the network up to a maximum size.\n",
      "A common approach is to define the design space in a way that enables a feasible exploration process and design an effective method for exploring it. Zoph & Le (2016) (NAS) first define a set of hyper-parameters characterizing a layer (number of filters, kernel size, stride). Then they use a controller-RNN for finding the optimal sequence of layer configurations for a \"trainee network\". This is done using policy gradients (REINFORCE) for optimizing the objective function that is based on the accuracy achieved by the \"trainee\" on a validation set. Although this work demonstrates capabilities to solve large-scale problems (Imagenet), it comes with huge computational cost. In a following work, Zoph et al. (2017) address the same problem but apply a hierarchical approach. They use NAS to design network modules on a small-scale dataset (CIFAR-10) and transfer this knowledge to a large-scale problem by learning the optimal topology composed of these modules. Baker et al. (2016) use reinforcement learning as well and apply Q-learning with epsilon-greedy exploration strategy and experience replay. Negrinho & Gordon (2017) propose a language that allows a human expert to compactly represent a complex search-space over architectures and hyperparameters as a tree and then use methods such as MCTS or SMBO to traverse this tree. Smithson et al. (2016) present a multi objective design space exploration, taking into account not only the classification accuracy but also the computational cost. In order to reduce the cost involved in evaluating the network's accuracy, they train a Response Surface Model that predicts the accuracy at much lower cost, reducing the number of candidates that go through actual validation accuracy evaluation. Another common approach for architecture search is based on evolutionary strategies to define and search the design space. (Real et al., 2017;Miikkulainen et al., 2017) use evolutionary algorithm to evolve an initial model or blueprint based on its validation performance.\n",
      "Common to all these recent studies is the fact that structure learning is done in a supervised manner, eventually learning a discriminative model. Moreoever, these approaches require huge compute resources, rendering the solution unfeasible for most applications given limited compute and time resources.\n",
      "PAPER EXPERIMENTS:\n",
      "We evaluate the quality of the learned structure in two experiments:\n",
      "• Classification accuracy as a function of network depth and size for a structure learned directly from MNIST pixels.\n",
      "• Classification accuracy as a function of network size on a range of benchmarks and compared to common topologies.\n",
      "All the experiments were repeated five times where average and standard deviation of the classification accuracy were recorded. In all of our experiments, we used a ReLU function for activation, ADAM (Kingma & Ba, 2015) for optimization, and applied batch normalization (Ioffe & Szegedy, 2015) followed by dropout (Srivastava et al., 2014) to all the dense layers. All optimization hyperparameters that were tuned for the vanilla topologies were also used, without additional tuning, for the learned structures. For the learned structures, all layers were allocated an equal number of neurons. Threshold for independence tests, and the number of neurons-per-layer were selected by using a validation set. Only test-set accuracy is reported.\n",
      "Our structure learning algorithm was implemented using the Bayesian network toolbox (Murphy, 2001) and Matlab. We used Torch7 (Collobert et al., 2011a) and Keras (Chollet, 2015) with the TensorFlow (Abadi et al., 2015) back-end for optimizing the parameters of both the vanilla and learned structures.\n",
      "PAPER NETWORK DEPTH, NUMBER OF PARAMETERS, AND ACCURACY:\n",
      "We analyze the accuracy of structures learned by our algorithm as a function of the number of layers and parameters. Although network depth is automatically determined by the algorithm, it is implicitly controlled by the threshold used to test conditional independence (partial-correlation test in our experiments). For example, a high threshold may cause detection of many independencies leading to early termination of the algorithm and a shallow network (a low threshold has the opposite effect). Thus, four different networks having 2, 3, 4, and 5 layers, using four different thresholds, are learned for MNIST. We also select three configurations of network sizes: a baseline (normalized to 1.00), and two configurations in which the number of parameters is 0.5, and 0.375 of the baseline network (equal number of neurons are allocated for each layer).\n",
      "Classification accuracies are summarized in Table 1. When the number of neurons-per-layers is large enough (100%) a 3-layer network achieves the highest classification accuracy of 99.07% (standard deviation is 0.01) where a 2-layer dense network has only a slight degradation in accuracy, 99.04%. For comparison, networks with 2 and 3 fully connected layers (structure is not learned) with similar number of parameters achieve 98.4% and 98.75%, respectively. This demonstrates the efficiency of our algorithm when learning a structure having a small number of layers. In addition, for a smaller neuron allocation (50%), deeper structures learned by our algorithm have higher accuracy than shallower ones. However, a decrease in the neurons-per-layer allocation has a greater impact on accuracy for deeper structures.  MNIST images as a function of network depth and number of parameters (normalized). For comparison, when a structure is not learned, networks with 2 and 3 dense layers, achieve 98.4% and 98.75% accuracy, respectively (having the same size as learned structures at configuration \"100%\").\n",
      "PAPER LEARNING THE STRUCTURE OF THE DEEPEST LAYERS IN COMMON TOPOLOGIES:\n",
      "We evaluate the quality of learned structures using five image classification benchmarks. We compare the learned structures to common topologies (and simpler hand-crafted structures), which we call \"vanilla topologies\", with respect to network size and classification accuracy. The benchmarks and vanilla topologies are described in  In the first row we indicate that in one experiment a structure for MNIST was learned from the pixels and feature extracting convolutional layers were not used.\n",
      "Convolutional layers are powerful feature extractors for images exploiting domain knowledge, such as spatial smoothness, translational invariance, and symmetry. We therefore evaluate our algorithm by using the first convolutional layers of the vanilla topologies as \"feature extractors\" (mostly below 50% of the vanilla network size) and learning a deep structure from their output. That is, the deepest layers of the vanilla network (mostly over 50% of the network size) is removed and replaced by a structure learned by our algorithm in an unsupervised manner. Finally, a softmax layer is added and the entire network parameters are optimized.\n",
      "First, we demonstrate the effect of replacing a different amount of the deepest layers and the ability of the learned structure to replace feature extraction layers.  VGG-16 is the \"vanilla\" topology. For both, CIFAR 10/100 benchmarks, the learned structure achieves the highest accuracy by replacing all the layers that are deeper than layer conv.10. Moreover, accuracy is maintained when replacing the layers deeper than layer conv.7.\n",
      "One interesting phenomenon to note is that the highest accuracy is achieved at conv. 10 rather than at the \"classifier\" (the last dense layer). This might imply that although convolutional layers are useful at extracting features directly from images, they might be redundant for deeper layers. By using our structure learning algorithm to learn the deeper layers, accuracy of the overall structure increases with the benefit of having a compact network. An accuracy, similar to that of \"vanilla\" VGG-16, is achieved with a structure having 85% less total parameters (conv. 7) than the vanilla network, where the learned structure is over 50X smaller than the replaced part.\n",
      "Next, we evaluate the accuracy of the learned structure as a function of the number of parameters and compare it to a densely connected network (fully connected layers) having the same depth and size. For SVHN, we used the Batch Normalized Maxout Network in Network topology (Chang & Chen, 2015) and removed the deepest layers starting from the output of the second NiN block (MMLP-2-2). For CIFAR-10, we used the VGG-16 and removed the deepest layers starting from the output of conv.10 layer. For MNIST, a structure was learned directly from pixels. Results are depicted in Figure 6. It is evident that accuracy of the learned structures is significantly higher (error bars represent 2 standard deviations) than a set of fully connected layers, especially in cases where the network is limited to a small number of parameters.\n",
      "[a]  Finally, in Table 4 we provide a summary of network sizes and classification accuracies, achieved by replacing the deepest layers of common topologies (vanilla) with a learned structure. In the first row, a structure is learned directly from images; therefore, it does not have a \"vanilla\" topology as reference (a network with 3 fully-connected layers having similar size achieves 98.75% accuracy). In all the cases, the size of the learned structure is significantly smaller than the vanilla topology, and generally has an increase in accuracy.\n",
      "Comparison to other methods. Our structure learning algorithm runs efficiently on a standard desktop CPU, while providing structures with competitive classification accuracies and network sizes. For example, the lowest classification error rate achieved by our unsupervised algorithm for CIFAR 10 is 4.58% with a network of size 6M (WRN-40-4 row in Table 4). For comparison, the NAS algorithm (Zoph & Le, 2016) achieves error rates of 5.5% and 4.47% for networks of sizes 4.2M and 7.1M, respectively, and requires optimizing thousands of networks using hundreds of GPUs. For AlexNet network, recent methods for reducing the size of a pre-trained network (pruning while maintaining classification accuracy) achieve 5× (Denton et al., 2014) and 9× (Han et al., 2015;2016)   The number of parameters are reported for \"feature extraction\" (first layers of the vanilla topology), removed section (the deepest layers of the vanilla topology), and the learned structure that replaced the removed part. The sum of parameters in the \"feature extraction\" and removed parts equals to the vanilla topology size. The first row corresponds to learning a structure directly from image pixels.\n",
      "PAPER CONCLUSIONS:\n",
      "We presented a principled approach for learning the structure of deep neural networks. Our proposed algorithm learns in an unsupervised manner and requires small computational cost. The resulting structures encode a hierarchy of independencies in the input distribution, where a node in one layer may connect another node in any deeper layer, and depth is determined automatically.\n",
      "We demonstrated that our algorithm learns small structures, and maintains high classification accuracies for common image classification benchmarks. It is also demonstrated that while convolution layers are very useful at exploiting domain knowledge, such as spatial smoothness, translational invariance, and symmetry, they are mostly outperformed by a learned structure for the deeper layers. Moreover, while the use of common topologies (meta-architectures), for a variety of classification tasks is computationally inefficient, we would expect our approach to learn smaller and more accurate networks for each classification task, uniquely.\n",
      "As only unlabeled data is required for learning the structure, we expect our approach to be practical for many domains, beyond image classification, such as knowledge discovery, and plan to explore the interpretability of the learned structures.\n",
      "PAPER APPENDIX A PRESERVATION OF CONDITIONAL DEPENDENCE:\n",
      "Conditional dependence relations encoded by the genrative structure G are preserved by the discriminative structure G D conditioned on the class Y . That is, G D conditioned on Y can mimic G; denoted by preference relation G G D |Y . While the parameters of a model can learn to mimic conditional independence relations that are not expressed by the graph structure, they are not able to learn conditional dependence relations (Pearl, 2009). Proposition 1. Graph G Inv preserves all conditional dependencies in G (i.e., G G Inv ).\n",
      "Proof. Graph G Inv can be constructed using the procedures described by Stuhlmüller et al. (2013) where nodes are added, one-by-one, to G Inv in a reverse topological order (lowest first) and connected (as a child) to existing nodes in G Inv that d-separate it, according to G, from the remainder of G Inv . Paige & Wood (2016) showed that this method ensures the preservation of conditional dependence G G Inv . We set an equal topological order to every pair of latents (H i , H j ) sharing a common child in G. Hence, jointly adding nodes H i and H j to G Inv , connected by a bi-directional edge, requires connecting them (as children) only to their children and the parents of their children (H i and H j themselves, by definition) in G. That is, without loss of generality, node H i is d-separated from the remainder of G Inv given its children in G and H j .\n",
      "It is interesting to note that the stochastic inverse G Inv , constructed without adding inter-layer connections, preserves all conditional dependencies in G.\n",
      "Proof. It is only required to prove that the dependency relations that are represented by bi-directional edges in G Inv are preserved in G D . The proof follows directly from the d-separation criterion (Pearl, 2009). A latent pair {H, H } ⊂ H (n+1) , connected by a bi-directional edge in G Inv , cannot be d-separated by any set containing Y , as Y is a descendant of a common child of H and H . In Algorithm 2-line 12, a latent in H (n) is connected, as a child, to latents H (n+1) , and Y to H (0) . We formulate G Inv as a projection of another latent model (Pearl, 2009) where bi-directional edges represent dependency relations induced by latent variables Q. We construct a discriminative model by considering the effect of Q as an explaining-away relation induced by a class node Y . Thus, conditioned on Y , the discriminative graph G D preserves all conditional (and marginal) dependencies in G Inv . Proposition 3. Graph G D , conditioned on Y , preserves all conditional dependencies in G (i.e., G G D ).\n",
      "PAPER Proof. It immediately follows from Propositions:\n",
      "\n",
      "\n",
      "Assistant: This is the review:\n",
      "REVIEW title:\n",
      "There is a major technical flaw in this paper. And some experiment settings are not convincing.\n",
      "REVIEW rating:\n",
      "4: Ok but not good enough - rejection\n",
      "REVIEW review:\n",
      "The paper proposes an unsupervised structure learning method for deep neural networks. It first constructs a fully visible DAG by learning from data, and decomposes variables into autonomous sets. Then latent variables are introduced and stochastic inverse is generated. Later a deep neural network structure is constructed based on the discriminative graph. Both the problem considered in the paper and the proposed method look interesting. The resulting structure seems nice.\n",
      "However, the reviewer indeed finds a major technical flaw in the paper. The foundation of the proposed method is on preserving the conditional dependencies in graph G. And each step mentioned in the paper, as it claims, can preserve all the conditional dependencies. However, in section 2.2, it seems that the stochastic inverse cannot. In Fig. 3(b), A and B are no longer dependent conditioned on {C,D,E} due to the v-structure induced in node H_A and H_B. Also in Fig. 3(c), if the reviewer understands correctly, the bidirectional edge between H_A and H_B is equivalent to H_A <- h -> H_B, which also induces a v-structure, blocking the dependency between A and B. Therefore, the very foundation of the proposed method is shattered. And the reviewer requests an explicit explanation of this issue.\n",
      "Besides that, the reviewer also finds unfair comparisons in the experiments.\n",
      "1. In section 5.1, although the authors show that the learned structure achieves 99.04%-99.07% compared with 98.4%-98.75% for fully connected layers, the comparisons are made by keeping the number of parameters similar in both cases. The comparisons are reasonable but not very convincing. Observing that the learned structures would be much sparser than the fully connected ones, it means that the number of neurons in the fully connected network is significantly smaller. Did the authors compare with fully connected network with similar number of neurons? In such case, which one is better? (Having fewer parameters is a plus, but in terms of accuracy the number of neurons really matters for fair comparison. In practice, we definitely would not use that small number of neurons in fully connected layers.)\n",
      "2. In section 5.2, it is interesting to observe that using features from conv10 is better than that from last dense layer. But it is not a fair comparison with vanilla network. In vanilla VGG-16-D, there are 3 more conv layers and 3 more fully connected layers. If you find that taking features from conv10 is good for the learned structure, then maybe it will also be good by taking features from conv10 and then apply 2-3 fully-connected layers directly (The proposed structure learning is not comparable to convolutional layers, and what it should really compare to is fully-connected layers.) In such case, which one is better? \n",
      "Secondly, VGG-16 is a large network designed for ImageNet data. For small dataset such as CIFAR10 and CIFAR100, it is really overkilled. That's maybe the reason why taking the output of shallow layers could achieve pretty good results.\n",
      "3. In Fig. 6, again, comparing the learned structure with fully-connected network by keeping parameters to be similar and resulting in large difference of the number of neurons is unfair from my point of view.\n",
      "Furthermore, all the comparisons are made with respect to fully-connected network or vanilla CNNs. No other structure learning methods are compared with. Reasonable baseline methods should be included.\n",
      "In conclusion, due to the above issues both in method and experiments, the reviewer thinks that this paper is not ready for publication.\n",
      "REVIEW confidence:\n",
      "4: The reviewer is confident but not absolutely certain that the evaluation is correct\n"
     ]
    }
   ],
   "source": [
    "# 进行单轮转换\n",
    "template_single = \"User: Please reivew this paper or give some sugguestion.\\n\\nAssistant: Ok, please provide detailed infomation or provide paper to review.\\n\\nUser: This is the paper:\\n{}\\n\\nAssistant: This is the review:\\n{}\"\n",
    "\n",
    "def make_single(row, template=template_single):\n",
    "    return template_single.format(row[\"paper\"], row[\"review\"])\n",
    "\n",
    "df_merge_drop[\"final_text_single\"] = df_merge_drop.apply(lambda x: make_single(x), axis=1)\n",
    "print(df_merge_drop[\"final_text_single\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57d29061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17881/17881 [00:03<00:00, 5903.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# 保存为jsonl文件，每个元素为单条数据\n",
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "\n",
    "single_jsonl_path = \"single_data.jsonl\"\n",
    "for final_text_single in tqdm(df_merge_drop[\"final_text_single\"]):\n",
    "    dict_text_single = {\"text\": final_text_single}\n",
    "    with jsonlines.open(single_jsonl_path, mode=\"a\") as file_single:\n",
    "        file_single.write(dict_text_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f9adb8",
   "metadata": {},
   "source": [
    "### II. 多轮形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f23f7943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Please reivew this paper or give some sugguestion.\n",
      "\n",
      "Assistant: Ok, please provide detailed infomation or provide paper to review.\n",
      "\n",
      "User: This is the paper:\n",
      "{paper}\n",
      "\n",
      "Assistant: This is the review:\n",
      "{reivew1}\n",
      "\n",
      "User: Any more?\n",
      "\n",
      "Assistant:\n",
      "{review2}\n",
      "\n",
      "User: Any more?\n",
      "\n",
      "Assistant:\n",
      "{review3}\n"
     ]
    }
   ],
   "source": [
    "# 多轮组织格式展示\n",
    "template_multiple_show = \"User: Please reivew this paper or give some sugguestion.\\n\\nAssistant: Ok, please provide detailed infomation or provide paper to review.\\n\\nUser: This is the paper:\\n{paper}\\n\\nAssistant: This is the review:\\n{reivew1}\\n\\nUser: Any more?\\n\\nAssistant:\\n{review2}\\n\\nUser: Any more?\\n\\nAssistant:\\n{review3}\"\n",
    "print(template_multiple_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6378ebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3837/3837 [00:01<00:00, 3105.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# 保存为jsonl文件，每个元素为单条数据\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "template_multiple_head = \"User: Please reivew this paper or give some sugguestion.\\n\\nAssistant: Ok, please provide detailed infomation or provide paper to review.\"\n",
    "template_multiple_first = \"User: This is the paper:\\n{}\\n\\nAssistant: This is the review:\\n{}\"\n",
    "template_multiple_round = \"User: Any more?\\n\\nAssistant: This is another review:\\n{}\"\n",
    "\n",
    "\n",
    "multiple_jsonl_path = \"multiple_data.jsonl\"\n",
    "for idx, fm in tqdm(df_merge_drop.groupby(\"forum\")):\n",
    "    thepaper = fm[\"paper\"].iloc[0]\n",
    "    template_multiple_list = []\n",
    "    for order, rv in enumerate(fm.sort_values(by=\"r_order\", ascending=True)[\"review\"]):\n",
    "        if order == 0:\n",
    "            template_multiple_list.append(template_multiple_head)\n",
    "            template_multiple_list.append(template_multiple_first.format(thepaper, rv))\n",
    "        else:\n",
    "            template_multiple_list.append(template_multiple_round.format(rv))\n",
    "    final_text_multiple = \"\\n\\n\".join(template_multiple_list)\n",
    "    if final_text_multiple:\n",
    "        dict_text_multiple = {\"text\": final_text_multiple}\n",
    "        with jsonlines.open(multiple_jsonl_path, mode=\"a\") as file_multiple:\n",
    "            file_multiple.write(dict_text_multiple)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acagpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
